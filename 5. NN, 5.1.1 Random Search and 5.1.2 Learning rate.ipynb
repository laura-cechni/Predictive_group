{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c14ee7-232a-4cc9-a97d-a002a5147eed",
   "metadata": {},
   "source": [
    "#Â Building NNs with LLMs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7816d-aa48-45ee-bfdd-97f916edea04",
   "metadata": {},
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1858603-3bd2-48d0-923b-772501925c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_recommenders in /usr/local/lib/python3.11/site-packages (0.7.3)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.11/site-packages (from tensorflow_recommenders) (2.1.0)\n",
      "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.11/site-packages (from tensorflow_recommenders) (2.15.0.post1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.26.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (65.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow_recommenders) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/site-packages (from keras-tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display, Code\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "!pip install tensorflow_recommenders\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c67f84-7c74-474b-bfa9-ec81da28722b",
   "metadata": {},
   "source": [
    "Helper Functions for LLM Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd0e29fb-68e0-476d-add7-c9046562fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='H_ClMkEoDcpQkDU4iYaTd3UNMuUUdPDbeQbDVHMnGms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68866a76-7ea8-4e5a-97c3-7232f0653b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resp_oai(input_text, model):\n",
    "    url = \"https://llm.api.ai8.io/query_llm\"\n",
    "    data = {\n",
    "        # Specify the model that you want to use\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You act as a highly intelligent system. Your job is to analyse the movie data and predict the rating scores of movies considering various movie features\"},\n",
    "                    {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    }\n",
    "    headers = {'Authorization': api_key}\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        response_data = json.loads(response.content)\n",
    "        model_response = extract_message_oai(response_data)\n",
    "        return model_response\n",
    "    else:\n",
    "        return {\"statusCode\": response.status_code, \"body\": response.content}\n",
    "\n",
    "def extract_message_oai(response_data):\n",
    "    message_content = response_data.get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    # format the extracted message as markdown\n",
    "    markdown_content = \"---\\n\\n\" + message_content + \"\\n\\n---\"\n",
    "    return markdown_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f876dc6-f3ec-4e2e-8c95-4aec9ca73a62",
   "metadata": {},
   "source": [
    "Inspect data: to create effective propmts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e9e4405-068f-485c-b081-0477f7bd5aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>director_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>actor_1_name</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>actor_3_name</th>\n",
       "      <th>movie_imdb_link</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>Genre_Western</th>\n",
       "      <th>duration_category</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>budget_category</th>\n",
       "      <th>revenue_category</th>\n",
       "      <th>budget_revenue_ratio</th>\n",
       "      <th>log_budget</th>\n",
       "      <th>log_revenue</th>\n",
       "      <th>log_title_year</th>\n",
       "      <th>sqr_root_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>Wes Studi</td>\n",
       "      <td>http://www.imdb.com/title/tt0499549/?ref_=fn_t...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>165-180 Minutes</td>\n",
       "      <td>07-Aug</td>\n",
       "      <td>Greater than 200 Million</td>\n",
       "      <td>Greater than 1.8 Billion</td>\n",
       "      <td>0.085009</td>\n",
       "      <td>19.283571</td>\n",
       "      <td>21.748578</td>\n",
       "      <td>7.605890</td>\n",
       "      <td>13.341664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>Pirates of the Caribbean At Worlds End</td>\n",
       "      <td>Jack Davenport</td>\n",
       "      <td>http://www.imdb.com/title/tt0449088/?ref_=fn_t...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>165-180 Minutes</td>\n",
       "      <td>07-Aug</td>\n",
       "      <td>Greater than 200 Million</td>\n",
       "      <td>800-1000 Million</td>\n",
       "      <td>0.312176</td>\n",
       "      <td>19.519293</td>\n",
       "      <td>20.683485</td>\n",
       "      <td>7.604894</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>Christoph Waltz</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>Stephanie Sigman</td>\n",
       "      <td>http://www.imdb.com/title/tt2379713/?ref_=fn_t...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>135-150 Minutes</td>\n",
       "      <td>06-Jul</td>\n",
       "      <td>Greater than 200 Million</td>\n",
       "      <td>800-1000 Million</td>\n",
       "      <td>0.278197</td>\n",
       "      <td>19.316769</td>\n",
       "      <td>20.596199</td>\n",
       "      <td>7.608871</td>\n",
       "      <td>12.165525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Joseph Gordon-Levitt</td>\n",
       "      <td>http://www.imdb.com/title/tt1345836/?ref_=fn_t...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>150-165 Minutes</td>\n",
       "      <td>08-Sep</td>\n",
       "      <td>Greater than 200 Million</td>\n",
       "      <td>1-1.20 Billion</td>\n",
       "      <td>0.230429</td>\n",
       "      <td>19.336971</td>\n",
       "      <td>20.804790</td>\n",
       "      <td>7.607381</td>\n",
       "      <td>12.806248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>132.0</td>\n",
       "      <td>Samantha Morton</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>Daryl Sabara</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>Polly Walker</td>\n",
       "      <td>http://www.imdb.com/title/tt0401729/?ref_=fn_t...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>120-135 Minutes</td>\n",
       "      <td>06-Jul</td>\n",
       "      <td>Greater than 200 Million</td>\n",
       "      <td>200-400 Million</td>\n",
       "      <td>0.915046</td>\n",
       "      <td>19.376192</td>\n",
       "      <td>19.464974</td>\n",
       "      <td>7.607381</td>\n",
       "      <td>11.489125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      director_name  duration      actor_2_name  \\\n",
       "0           0      James Cameron     178.0  Joel David Moore   \n",
       "1           1     Gore Verbinski     169.0     Orlando Bloom   \n",
       "2           2         Sam Mendes     148.0      Rory Kinnear   \n",
       "3           3  Christopher Nolan     164.0    Christian Bale   \n",
       "4           4     Andrew Stanton     132.0   Samantha Morton   \n",
       "\n",
       "                          genres_x     actor_1_name  \\\n",
       "0  Action|Adventure|Fantasy|Sci-Fi      CCH Pounder   \n",
       "1         Action|Adventure|Fantasy      Johnny Depp   \n",
       "2        Action|Adventure|Thriller  Christoph Waltz   \n",
       "3                  Action|Thriller        Tom Hardy   \n",
       "4          Action|Adventure|Sci-Fi     Daryl Sabara   \n",
       "\n",
       "                              movie_title          actor_3_name  \\\n",
       "0                                  Avatar             Wes Studi   \n",
       "1  Pirates of the Caribbean At Worlds End        Jack Davenport   \n",
       "2                                 Spectre      Stephanie Sigman   \n",
       "3                   The Dark Knight Rises  Joseph Gordon-Levitt   \n",
       "4                             John Carter          Polly Walker   \n",
       "\n",
       "                                     movie_imdb_link language  ...  \\\n",
       "0  http://www.imdb.com/title/tt0499549/?ref_=fn_t...  English  ...   \n",
       "1  http://www.imdb.com/title/tt0449088/?ref_=fn_t...  English  ...   \n",
       "2  http://www.imdb.com/title/tt2379713/?ref_=fn_t...  English  ...   \n",
       "3  http://www.imdb.com/title/tt1345836/?ref_=fn_t...  English  ...   \n",
       "4  http://www.imdb.com/title/tt0401729/?ref_=fn_t...  English  ...   \n",
       "\n",
       "  Genre_Western  duration_category  rating_category           budget_category  \\\n",
       "0             0    165-180 Minutes           07-Aug  Greater than 200 Million   \n",
       "1             0    165-180 Minutes           07-Aug  Greater than 200 Million   \n",
       "2             0    135-150 Minutes           06-Jul  Greater than 200 Million   \n",
       "3             0    150-165 Minutes           08-Sep  Greater than 200 Million   \n",
       "4             0    120-135 Minutes           06-Jul  Greater than 200 Million   \n",
       "\n",
       "           revenue_category  budget_revenue_ratio log_budget  log_revenue  \\\n",
       "0  Greater than 1.8 Billion              0.085009  19.283571    21.748578   \n",
       "1          800-1000 Million              0.312176  19.519293    20.683485   \n",
       "2          800-1000 Million              0.278197  19.316769    20.596199   \n",
       "3            1-1.20 Billion              0.230429  19.336971    20.804790   \n",
       "4           200-400 Million              0.915046  19.376192    19.464974   \n",
       "\n",
       "   log_title_year  sqr_root_duration  \n",
       "0        7.605890          13.341664  \n",
       "1        7.604894          13.000000  \n",
       "2        7.608871          12.165525  \n",
       "3        7.607381          12.806248  \n",
       "4        7.607381          11.489125  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "final_movies = pd.read_csv(\"final_merged_df.csv\")\n",
    "final_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8beedbbe-0efb-486d-9b25-cce3b27fe2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'director_name', 'duration', 'actor_2_name', 'genres_x',\n",
       "       'actor_1_name', 'movie_title', 'actor_3_name', 'movie_imdb_link',\n",
       "       'language', 'country', 'title_year', 'imdb_score', 'budget',\n",
       "       'original_title', 'revenue', 'tagline', 'Genre_Action',\n",
       "       'Genre_Adventure', 'Genre_Animation', 'Genre_Biography', 'Genre_Comedy',\n",
       "       'Genre_Crime', 'Genre_Documentary', 'Genre_Drama', 'Genre_Family',\n",
       "       'Genre_Fantasy', 'Genre_Film-Noir', 'Genre_History', 'Genre_Horror',\n",
       "       'Genre_Music', 'Genre_Musical', 'Genre_Mystery', 'Genre_News',\n",
       "       'Genre_Romance', 'Genre_Sci-Fi', 'Genre_Sport', 'Genre_Thriller',\n",
       "       'Genre_War', 'Genre_Western', 'duration_category', 'rating_category',\n",
       "       'budget_category', 'revenue_category', 'budget_revenue_ratio',\n",
       "       'log_budget', 'log_revenue', 'log_title_year', 'sqr_root_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23e429-f0a2-47b3-9c57-e6b11af2e382",
   "metadata": {},
   "source": [
    "Helper Functions to Define Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0530db-0bf8-41a8-9430-cd8b87e93857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to define the main task : prompt 1\n",
    "def define_prompt():\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "\n",
    "Task Description:\n",
    "Develop a neural network model using TensorFlow Recommenders to predict movie ratings based on the provided dataset. Your task is to design and implement a TensorFlow Recommenders model that accurately predicts movie ratings.\n",
    "\n",
    "Dataset:\n",
    "- Format: The dataset is named as 'final_movies' and is read in a CSV format with rows for each movie and columns containing information about movies. It consists of 4144 rows and 49 columns. This dataset provides a comprehensive set of features related to movies, including director, actors, genres, budget, revenue, and IMDb ratings, among others.\n",
    "\n",
    "- Columns:\n",
    "1. Unnamed: 0: Index column.\n",
    "2. director_name: Name of the movie director.\n",
    "3. duration: Duration of the movie in minutes.\n",
    "4. actor_2_name: Name of the second actor in the movie.\n",
    "5. genres_x: Genres of the movie.\n",
    "6. actor_1_name: Name of the lead actor in the movie.\n",
    "7. movie_title: Title of the movie.\n",
    "8. actor_3_name: Name of the third actor in the movie.\n",
    "9. movie_imdb_link: IMDb link of the movie.\n",
    "10. language: Language of the movie.\n",
    "11. country: Country where the movie was produced.\n",
    "12. title_year: Year of release of the movie.\n",
    "13. imdb_score: IMDb rating of the movie.\n",
    "14. budget: Budget of the movie.\n",
    "15. original_title: Original title of the movie.\n",
    "16. revenue: Revenue generated by the movie.\n",
    "17. tagline: Tagline of the movie.\n",
    "18. Genre_Action: Binary indicator for Action genre.\n",
    "19. Genre_Adventure: Binary indicator for Adventure genre.\n",
    "20. Genre_Animation: Binary indicator for Animation genre.\n",
    "21. Genre_Biography: Binary indicator for Biography genre.\n",
    "22. Genre_Comedy: Binary indicator for Comedy genre.\n",
    "23. Genre_Crime: Binary indicator for Crime genre.\n",
    "24. Genre_Documentary: Binary indicator for Documentary genre.\n",
    "25. Genre_Drama: Binary indicator for Drama genre.\n",
    "26. Genre_Family: Binary indicator for Family genre.\n",
    "27. Genre_Fantasy: Binary indicator for Fantasy genre.\n",
    "28. Genre_Film-Noir: Binary indicator for Film-Noir genre.\n",
    "29. Genre_History: Binary indicator for History genre.\n",
    "30. Genre_Horror: Binary indicator for Horror genre.\n",
    "31. Genre_Music: Binary indicator for Music genre.\n",
    "32. Genre_Musical: Binary indicator for Musical genre.\n",
    "33. Genre_Mystery: Binary indicator for Mystery genre.\n",
    "34. Genre_News: Binary indicator for News genre.\n",
    "35. Genre_Romance: Binary indicator for Romance genre.\n",
    "36. Genre_Sci-Fi: Binary indicator for Sci-Fi genre.\n",
    "37. Genre_Sport: Binary indicator for Sport genre.\n",
    "38. Genre_Thriller: Binary indicator for Thriller genre.\n",
    "39. Genre_War: Binary indicator for War genre.\n",
    "40. Genre_Western: Binary indicator for Western genre.\n",
    "41. duration_category: Categorized duration of the movie.\n",
    "42. rating_category: Categorized IMDb rating of the movie.\n",
    "43. budget_category: Categorized budget of the movie.\n",
    "44. revenue_category: Categorized revenue of the movie.\n",
    "45. budget_revenue_ratio: Ratio of budget to revenue.\n",
    "46. log_budget: Logarithm of the budget.\n",
    "47. log_revenue: Logarithm of the revenue.\n",
    "48. log_title_year: Logarithm of the title year.\n",
    "49. sqr_root_duration: Square root of the duration.\n",
    "\n",
    "- To give you a bit more context about the dataset, and its features, this is the output we get after performing .info() method of the pandas library on the dataset (which gives more details about the dataset and itâs features): \n",
    "\n",
    "RangeIndex: 4144 entries, 0 to 4143\n",
    "Data columns (total 49 columns):\n",
    " #   Column                Non-Null Count  Dtype  \n",
    "---  ------                --------------  -----  \n",
    " 0   Unnamed: 0            4144 non-null   int64  \n",
    " 1   director_name         4144 non-null   object \n",
    " 2   duration              4142 non-null   float64\n",
    " 3   actor_2_name          4140 non-null   object \n",
    " 4   genres_x              4144 non-null   object \n",
    " 5   actor_1_name          4141 non-null   object \n",
    " 6   movie_title           4144 non-null   object \n",
    " 7   actor_3_name          4135 non-null   object \n",
    " 8   movie_imdb_link       4144 non-null   object \n",
    " 9   language              4137 non-null   object \n",
    " 10  country               4144 non-null   object \n",
    " 11  title_year            4144 non-null   float64\n",
    " 12  imdb_score            4144 non-null   float64\n",
    " 13  budget                4144 non-null   int64  \n",
    " 14  original_title        4144 non-null   object \n",
    " 15  revenue               4144 non-null   float64\n",
    " 16  tagline               3584 non-null   object \n",
    " 17  Genre_Action          4144 non-null   int64  \n",
    " 18  Genre_Adventure       4144 non-null   int64  \n",
    " 19  Genre_Animation       4144 non-null   int64  \n",
    " 20  Genre_Biography       4144 non-null   int64  \n",
    " 21  Genre_Comedy          4144 non-null   int64  \n",
    " 22  Genre_Crime           4144 non-null   int64  \n",
    " 23  Genre_Documentary     4144 non-null   int64  \n",
    " 24  Genre_Drama           4144 non-null   int64  \n",
    " 25  Genre_Family          4144 non-null   int64  \n",
    " 26  Genre_Fantasy         4144 non-null   int64  \n",
    " 27  Genre_Film-Noir       4144 non-null   int64  \n",
    " 28  Genre_History         4144 non-null   int64  \n",
    " 29  Genre_Horror          4144 non-null   int64  \n",
    " 30  Genre_Music           4144 non-null   int64  \n",
    " 31  Genre_Musical         4144 non-null   int64  \n",
    " 32  Genre_Mystery         4144 non-null   int64  \n",
    " 33  Genre_News            4144 non-null   int64  \n",
    " 34  Genre_Romance         4144 non-null   int64  \n",
    " 35  Genre_Sci-Fi          4144 non-null   int64  \n",
    " 36  Genre_Sport           4144 non-null   int64  \n",
    " 37  Genre_Thriller        4144 non-null   int64  \n",
    " 38  Genre_War             4144 non-null   int64  \n",
    " 39  Genre_Western         4144 non-null   int64  \n",
    " 40  duration_category     4142 non-null   object \n",
    " 41  rating_category       4144 non-null   object \n",
    " 42  budget_category       3430 non-null   object \n",
    " 43  revenue_category      3126 non-null   object \n",
    " 44  budget_revenue_ratio  3552 non-null   float64\n",
    " 45  log_budget            4144 non-null   float64\n",
    " 46  log_revenue           4144 non-null   float64\n",
    " 47  log_title_year        4144 non-null   float64\n",
    " 48  sqr_root_duration     4142 non-null   float64\n",
    "dtypes: float64(9), int64(25), object(15)\n",
    "memory usage: 1.5+ MB\n",
    "\n",
    "Dataset head in a JSON format: \n",
    "'{\"Unnamed: 0\":{\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4},\"director_name\":{\"0\":\"James Cameron\",\"1\":\"Gore Verbinski\",\"2\":\"Sam Mendes\",\"3\":\"Christopher Nolan\",\"4\":\"Andrew Stanton\"},\"duration\":{\"0\":178.0,\"1\":169.0,\"2\":148.0,\"3\":164.0,\"4\":132.0},\"actor_2_name\":{\"0\":\"Joel David Moore\",\"1\":\"Orlando Bloom\",\"2\":\"Rory Kinnear\",\"3\":\"Christian Bale\",\"4\":\"Samantha Morton\"},\"genres_x\":{\"0\":\"Action|Adventure|Fantasy|Sci-Fi\",\"1\":\"Action|Adventure|Fantasy\",\"2\":\"Action|Adventure|Thriller\",\"3\":\"Action|Thriller\",\"4\":\"Action|Adventure|Sci-Fi\"},\"actor_1_name\":{\"0\":\"CCH Pounder\",\"1\":\"Johnny Depp\",\"2\":\"Christoph Waltz\",\"3\":\"Tom Hardy\",\"4\":\"Daryl Sabara\"},\"movie_title\":{\"0\":\"Avatar\",\"1\":\"Pirates of the Caribbean At Worlds End\",\"2\":\"Spectre\",\"3\":\"The Dark Knight Rises\",\"4\":\"John Carter\"},\"actor_3_name\":{\"0\":\"Wes Studi\",\"1\":\"Jack Davenport\",\"2\":\"Stephanie Sigman\",\"3\":\"Joseph Gordon-Levitt\",\"4\":\"Polly Walker\"},\"movie_imdb_link\":{\"0\":\"http:\\\\/\\\\/www.imdb.com\\\\/title\\\\/tt0499549\\\\/?ref_=fn_tt_tt_1\",\"1\":\"http:\\\\/\\\\/www.imdb.com\\\\/title\\\\/tt0449088\\\\/?ref_=fn_tt_tt_1\",\"2\":\"http:\\\\/\\\\/www.imdb.com\\\\/title\\\\/tt2379713\\\\/?ref_=fn_tt_tt_1\",\"3\":\"http:\\\\/\\\\/www.imdb.com\\\\/title\\\\/tt1345836\\\\/?ref_=fn_tt_tt_1\",\"4\":\"http:\\\\/\\\\/www.imdb.com\\\\/title\\\\/tt0401729\\\\/?ref_=fn_tt_tt_1\"},\"language\":{\"0\":\"English\",\"1\":\"English\",\"2\":\"English\",\"3\":\"English\",\"4\":\"English\"},\"country\":{\"0\":\"USA\",\"1\":\"USA\",\"2\":\"UK\",\"3\":\"USA\",\"4\":\"USA\"},\"title_year\":{\"0\":2009.0,\"1\":2007.0,\"2\":2015.0,\"3\":2012.0,\"4\":2012.0},\"imdb_score\":{\"0\":7.9,\"1\":7.1,\"2\":6.8,\"3\":8.5,\"4\":6.6},\"budget\":{\"0\":237000000,\"1\":300000000,\"2\":245000000,\"3\":250000000,\"4\":260000000},\"original_title\":{\"0\":\"Avatar\",\"1\":\"Pirates of the Caribbean At Worlds End\",\"2\":\"Spectre\",\"3\":\"The Dark Knight Rises\",\"4\":\"John Carter\"},\"revenue\":{\"0\":2787965087.0,\"1\":961000000.0,\"2\":880674609.0,\"3\":1084939099.0,\"4\":284139100.0},\"tagline\":{\"0\":\"Enter the World of Pandora.\",\"1\":\"At the end of the world, the adventure begins.\",\"2\":\"A Plan No One Escapes\",\"3\":\"The Legend Ends\",\"4\":\"Lost in our world, found in another.\"},\"Genre_Action\":{\"0\":1,\"1\":1,\"2\":1,\"3\":1,\"4\":1},\"Genre_Adventure\":{\"0\":1,\"1\":1,\"2\":1,\"3\":0,\"4\":1},\"Genre_Animation\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Biography\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Comedy\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Crime\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Documentary\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Drama\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Family\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Fantasy\":{\"0\":1,\"1\":1,\"2\":0,\"3\":0,\"4\":0},\"Genre_Film-Noir\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_History\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Horror\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Music\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Musical\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Mystery\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_News\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Romance\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Sci-Fi\":{\"0\":1,\"1\":0,\"2\":0,\"3\":0,\"4\":1},\"Genre_Sport\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Thriller\":{\"0\":0,\"1\":0,\"2\":1,\"3\":1,\"4\":0},\"Genre_War\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Genre_Western\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"duration_category\":{\"0\":\"165-180 Minutes\",\"1\":\"165-180 Minutes\",\"2\":\"135-150 Minutes\",\"3\":\"150-165 Minutes\",\"4\":\"120-135 Minutes\"},\"rating_category\":{\"0\":\"7-8\",\"1\":\"7-8\",\"2\":\"6-7\",\"3\":\"8-9\",\"4\":\"6-7\"},\"budget_category\":{\"0\":\"Greater than 200 Million\",\"1\":\"Greater than 200 Million\",\"2\":\"Greater than 200 Million\",\"3\":\"Greater than 200 Million\",\"4\":\"Greater than 200 Million\"},\"revenue_category\":{\"0\":\"Greater than 1.8 Billion\",\"1\":\"800-1000 Million\",\"2\":\"800-1000 Million\",\"3\":\"1-1.20 Billion\",\"4\":\"200-400 Million\"},\"budget_revenue_ratio\":{\"0\":0.0850092381,\"1\":0.3121758179,\"2\":0.2781968257,\"3\":0.2304286804,\"4\":0.9150457791},\"log_budget\":{\"0\":19.2835707033,\"1\":19.519293036,\"2\":19.3167687726,\"3\":19.3369714798,\"4\":19.3761921928},\"log_revenue\":{\"0\":21.7485778075,\"1\":20.683484968,\"2\":20.596198774,\"3\":20.8047896933,\"4\":19.4649744685},\"log_title_year\":{\"0\":7.6058900011,\"1\":7.6048944808,\"2\":7.6088706292,\"3\":7.6073814256,\"4\":7.6073814256},\"sqr_root_duration\":{\"0\":13.3416640641,\"1\":13.0,\"2\":12.1655250606,\"3\":12.8062484749,\"4\":11.4891252931}}'\n",
    "\n",
    "Objectives:\n",
    "* Utilise TensorFlow and TensorFlow Recommenders to build a neural network model.\n",
    "* The model should take relevant features from the dataset as input and predict movie ratings.\n",
    "* Experiment with different architectures, hyperparameters, and preprocessing techniques to optimise the model's performance.\n",
    "* Evaluate the model using appropriate metrics and provide insights into its performance.\n",
    "* Provide insights into the model's performance and potential areas for improvement.\n",
    "\n",
    "Deliverables:\n",
    "1. Python code implementing the TensorFlow Recommenders model for movie rating prediction.\n",
    "2. A paragraph in comments documenting the model development process, including:\n",
    "    * Description of the chosen architecture and rationale behind it.\n",
    "    * Explanation of preprocessing techniques applied to the dataset.\n",
    "    * Summary of experiments conducted to optimise the model's performance.\n",
    "    * Evaluation metrics used and results obtained from model evaluation.\n",
    "    * Insights into the model's performance and potential areas for improvement.\n",
    "\n",
    "Requirements:\n",
    "1. Use TensorFlow and tensorflow_recommenders library to build the model.\n",
    "2. Include relevant features from the dataset as input to the model.\n",
    "3. Experiment with at least two different model architectures.\n",
    "4. Perform preprocessing on the dataset as necessary for model training.\n",
    "5. Document the code clearly, including comments where necessary for clarity.\n",
    "6. Submit the Python code and in an executable format (to be then executed with the function âexec()â).\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78fafef0-1681-4ae3-a613-1f59f6493ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert response string into an executable format: prompt 3, 5\n",
    "def helper_extraction_prompt(resp_str):\n",
    "    return f\"Can you transform this string: {resp_str} into an executable string by extracting the python code and keeping the rest of the information as comments? Please place comment symbols where nessesary and keep in mind that the given response string will be executed in a python code chunk using the function :'exec(given_response_string).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0724e2e-4190-409b-808f-17eed8c1174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prompt the model for error resolution purposes given the error encountered and previous response as inputs: prompt 2,4\n",
    "def prompt_error(prev_response, err):\n",
    "    return f\"Given that the code you provided: {prev_response} gives this error: {err}, help me resolve it by changing the code you provided where nessesary, your reposne should be in an executable code format\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b0865-abb9-4fc1-8a8b-4a46af06d31f",
   "metadata": {},
   "source": [
    "### Prompt the Model and Display Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86d0f54a-87e4-4664-a067-c4a19f4282e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style='color: #34568B;'>\n",
       "\n",
       "---\n",
       "\n",
       "Given the task requirements and constraints, we can outline a potential solution for building a TensorFlow Recommenders model for predicting movie ratings. Due to this environment not supporting direct code execution or access to external libraries such as TensorFlow, I'll provide a detailed conceptual walkthrough and code blueprint that aligns with your deliverables and requirements.\n",
       "\n",
       "### Data Preprocessing\n",
       "Before moving to model building, it's important to preprocess the data:\n",
       "1. **Handle missing values** - Decide whether to fill missing values (e.g., with median or average for numerical columns and a placeholder value or the most common value for categorical columns) or to drop rows/columns with missing values.\n",
       "2. **Normalize numerical features** - Use MinMaxScaler or StandardScaler for features like duration, budget, and revenue.\n",
       "3. **Encode categorical features** - Use one-hot encoding or TensorFlow feature embedding for categorical fields such as director_name, actor names, genres, and country.\n",
       "\n",
       "### TensorFlow Recommenders Model Blueprint\n",
       "\n",
       "#### Import Necessary Libraries\n",
       "```python\n",
       "import tensorflow as tf\n",
       "from tensorflow.keras.models import Model\n",
       "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
       "from tensorflow.keras.optimizers import Adam\n",
       "```\n",
       "\n",
       "#### Model Architecture #1: Basic Embedding Model\n",
       "This example constructs a basic model that embeds categorical movie features and processes numerical features, aiming to predict movie ratings.\n",
       "\n",
       "##### Feature Engineering and Model Definition\n",
       "```python\n",
       "# Assuming the preprocessing steps are applied, and data is split into train and test sets.\n",
       "\n",
       "# Define input layers for each feature.\n",
       "# Note: The number of unique values and embedding dimensions should be adjusted based on the actual data.\n",
       "director_input = Input(shape=(1,), name=\"director_name\")\n",
       "director_embedding = Embedding(num_directors, embedding_dim)(director_input)\n",
       "director_vec = Flatten(name=\"Flatten_Directors\")(director_embedding)\n",
       "\n",
       "# Repeat similar blocks for other categorical features (e.g., actors, genres_x)\n",
       "\n",
       "# Numerical inputs do not need embedding\n",
       "duration_input = Input(shape=(1,), name=\"duration\")\n",
       "\n",
       "# Combine all feature inputs\n",
       "concat = Concatenate()([director_vec, /* other feature vectors, */, duration_input])\n",
       "\n",
       "# Fully connected layers\n",
       "fc = Dense(128, activation='relu')(concat)\n",
       "fc = Dense(32, activation='relu')(fc)\n",
       "\n",
       "# Output layer\n",
       "output = Dense(1, activation='linear')(fc)\n",
       "\n",
       "# Define model\n",
       "model = Model(inputs=[director_input, /* other inputs */], outputs=output)\n",
       "\n",
       "# Compile the model\n",
       "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
       "```\n",
       "\n",
       "#### Training and Evaluation\n",
       "```python\n",
       "# Assuming X_train, y_train, X_test, y_test are prepared with appropriate feature columns\n",
       "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
       "\n",
       "evaluation = model.evaluate(X_test, y_test)\n",
       "print(f\"Test Loss: {evaluation[0]}, Test MAE: {evaluation[1]}\")\n",
       "```\n",
       "\n",
       "#### Model Architecture #2: Advanced Model with Mixed Features\n",
       "For a more advanced model, consider including feature crosses, deeper embedding layers for high-cardinality features, and possibly recurrent architectures for handling sequence data (e.g., the sequence of actors might provide some contextual clue).\n",
       "\n",
       "### Experimental Summary (Hypothetical)\n",
       "Through experimentation, we might find that:\n",
       "- Higher embedding dimensions for directors and genres lead to better performance but increase the risk of overfitting.\n",
       "- Regularization techniques (such as dropout) are crucial to manage overfitting, especially with a complex model.\n",
       "- Normalizing numerical features generally results in better performance.\n",
       "- Model performance might vary significantly with different optimizers and learning rates, where Adam and a learning rate scheduler can be quite effective.\n",
       "\n",
       "### Evaluation and Insights\n",
       "We would use Mean Absolute Error (MAE) or Root Mean Squared Error (RMSE) as our main metrics to evaluate the model's performance due to the regression nature of the problem. Insights might reveal the importance of certain features over others and indicate potential data quality issues or areas where more data could enhance model accuracy.\n",
       "\n",
       "#### Potential Areas for Improvement\n",
       "- Incorporating more sophisticated feature engineering (e.g., polynomial features for numerical data).\n",
       "- Exploration of more complex model architectures or ensemble methods.\n",
       "- Extensive hyperparameter tuning and cross-validation to optimize model parameters effectively.\n",
       "\n",
       "```python\n",
       "# Reminder: This is a hypothetical implementation blueprint. Tailor model architectures, feature engineering, and training procedures to your specific dataset and use case.\n",
       "```\n",
       "\n",
       "Given the high-level overview and codes snippets, you should be able to implement a TensorFlow Recommenders model that learns from the movie dataset to predict ratings accurately. Remember, iteration over different model architectures and hyperparameters is key to finding the best performing model.\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt1 = define_prompt()\n",
    "msg_1 = get_resp_oai(prompt1,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfac7b-258d-452e-9549-550488d0c2db",
   "metadata": {},
   "source": [
    "Execute the code given in the response message using`exec()`, minimal syntax manipulation required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6337ed2b-1ba9-4e47-952b-abc484f2eba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 1\u001b[0;36m\n\u001b[0;31m    exec(msg_1[15:len(msg_1)-338].replace(\"path_to_final_movies.csv\", \"final_merged_df.csv\").replace(\"genre_Action\", \"Genre_Action\").replace(\"genre_Adventure\", \"Genre_Adventure\").replace(\"genre_Animation\", \"Genre_Animation\"))\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    task requirements and constraints, we can outline a potential solution for building a TensorFlow Recommenders model for predicting movie ratings. Due to this environment not supporting direct code execution or access to external libraries such as TensorFlow, I'll provide a detailed conceptual walkthrough and code blueprint that aligns with your deliverables and requirements.\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "exec(msg_1[15:len(msg_1)-338].replace(\"path_to_final_movies.csv\", \"final_merged_df.csv\").replace(\"genre_Action\", \"Genre_Action\").replace(\"genre_Adventure\", \"Genre_Adventure\").replace(\"genre_Animation\", \"Genre_Animation\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f670c-3b6f-4eaf-b987-8713aab5840d",
   "metadata": {},
   "source": [
    "Error Resultion Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "467fd48b-d952-4ef6-be5d-6c44b3cde0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = \"\"\" \n",
    "<string>:23: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "Epoch 1/10\n",
    "---------------------------------------------------------------------------\n",
    "NotImplementedError                       Traceback (most recent call last)\n",
    "Cell In[48], line 1\n",
    "----> 1 exec(msg_1[15:len(msg_1)-338].replace(\"path_to_final_movies.csv\", \"final_merged_df.csv\").replace(\"genre_Action\", \"Genre_Action\").replace(\"genre_Adventure\", \"Genre_Adventure\").replace(\"genre_Animation\", \"Genre_Animation\"))\n",
    "\n",
    "File <string>:73\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n",
    "     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "     68     # To get the full stack trace, call:\n",
    "     69     # `tf.debugging.disable_traceback_filtering()`\n",
    "---> 70     raise e.with_traceback(filtered_tb) from None\n",
    "     71 finally:\n",
    "     72     del filtered_tb\n",
    "\n",
    "File /tmp/__autograph_generated_filejo7rd7xr.py:15, in outer_factory.<locals>.inner_factory.<locals>.tf__train_function(iterator)\n",
    "     13 try:\n",
    "     14     do_return = True\n",
    "---> 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
    "     16 except:\n",
    "     17     do_return = False\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py:68, in Model.train_step(self, inputs)\n",
    "     65 Custom train step using the `compute_loss` method.\n",
    "     67 with tf.GradientTape() as tape:\n",
    "---> 68   loss = self.compute_loss(inputs, training=True)\n",
    "     70   # Handle regularization losses as well.\n",
    "     71   regularization_loss = sum(self.losses)\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py:61, in Model.compute_loss(self, inputs, training)\n",
    "     49 def compute_loss(self, inputs, training: bool = False) -> tf.Tensor:\n",
    "     50   Defines the loss function.\n",
    "     51 \n",
    "     52   Args:\n",
    "   (...)\n",
    "     58     Loss tensor.\n",
    "     59   \n",
    "---> 61   raise NotImplementedError(\n",
    "     62       \"Implementers must implement the `compute_loss` method.\")\n",
    "\n",
    "NotImplementedError: in user code:\n",
    "\n",
    "    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n",
    "        return step_function(self, iterator)\n",
    "    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n",
    "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
    "    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n",
    "        outputs = model.train_step(data)\n",
    "    File \"/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n",
    "        loss = self.compute_loss(inputs, training=True)\n",
    "    File \"/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py\", line 61, in compute_loss\n",
    "        raise NotImplementedError(\n",
    "\n",
    "    NotImplementedError: Implementers must implement the `compute_loss` method.\n",
    "\"\"\"\n",
    "\n",
    "prev_response = \"\"\"\n",
    "# Due to the constraints of this environment, I'm unable to run actual code or access external libraries such as TensorFlow.\n",
    "# However, I can provide a guided example code that you can run in your local environment.\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('path_to_final_movies.csv') # Replace path_to_final_movies.csv with the actual path of your dataset\n",
    "\n",
    "# Basic preprocessing\n",
    "# Fill missing values if necessary. For the purpose of this example, we'll assume minimal preprocessing.\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "\n",
    "# Feature engineering: Select features for the model\n",
    "# For simplicity, we'll use a subset of all available features.\n",
    "features = ['duration', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features]\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "# Convert Pandas dataframes to TensorFlow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((dict(train.drop('imdb_score', axis=1)), train['imdb_score']))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((dict(test.drop('imdb_score', axis=1)), test['imdb_score']))\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Define the model using TensorFlow Recommenders\n",
    "class MovieRatingModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = 32\n",
    "        \n",
    "        # Feature layers for various inputs\n",
    "        self.duration_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "        \n",
    "        # Final task model: Prediction of IMDb score\n",
    "        self.rating_prediction = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        duration_features = self.duration_model(inputs['duration'])\n",
    "        combined = tf.concat([duration_features, inputs['genre_Action'], inputs['genre_Adventure'], \n",
    "                              inputs['genre_Animation'], inputs['budget'], inputs['revenue']], axis=1)\n",
    "                              \n",
    "        return self.rating_prediction(combined)\n",
    "\n",
    "# Experiment with model architectures\n",
    "# For simplicity, this code does not explore multiple architectures as requested. You are encouraged to experiment with different layers and structures.\n",
    "\n",
    "model = MovieRatingModel()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.evaluate(test_ds)\n",
    "\n",
    "# Due to the synthetic nature of this example, the actual performance may vary. \n",
    "# It's recommended to experiment with different model configurations, feature selections, \n",
    "# and preprocessing steps to improve the model's accuracy.\n",
    "\n",
    "# Potential areas for improvement include: \n",
    "# - Including more features or embedding categorical features for better representation.\n",
    "# - Hyperparameter tuning to find the optimal model configuration. \n",
    "# - Utilizing more complex models or ensemble methods to capture non-linear relationships.\n",
    "# - Adding regularization to prevent overfitting.\n",
    "\n",
    "# Remember to adjust paths, feature selections, and model configurations as per your specific dataset and problem statement.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d5895a4-d7b0-4f5c-8b4b-feafd988c409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"o\">---</span>\n",
       "\n",
       "<span class=\"n\">It</span> <span class=\"n\">looks</span> <span class=\"n\">like</span> <span class=\"n\">you</span><span class=\"s1\">&#39;ve encountered two issues: a `SettingWithCopyWarning` warning from Pandas and a `NotImplementedError` from TensorFlow Recommenders due to the missing implementation of the `compute_loss` method in the `MovieRatingModel`. Here&#39;</span><span class=\"n\">s</span> <span class=\"n\">how</span> <span class=\"n\">you</span> <span class=\"n\">can</span> <span class=\"n\">address</span> <span class=\"n\">both</span> <span class=\"n\">issues</span><span class=\"p\">:</span>\n",
       "\n",
       "<span class=\"n\">For</span> <span class=\"n\">the</span> <span class=\"n\">Pandas</span> <span class=\"n\">warning</span><span class=\"p\">,</span> <span class=\"n\">it</span><span class=\"s1\">&#39;s best to perform operations on a DataFrame copy to avoid unintentional edits to your original DataFrame or to use the `.loc` method to ensure changes are made explicitly. For the TensorFlow error, you&#39;</span><span class=\"n\">ll</span> <span class=\"n\">need</span> <span class=\"n\">to</span> <span class=\"n\">implement</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"n\">compute_loss</span><span class=\"err\">`</span> <span class=\"n\">method</span> <span class=\"n\">within</span> <span class=\"n\">your</span> <span class=\"n\">model</span> <span class=\"n\">class</span><span class=\"o\">.</span> <span class=\"n\">However</span><span class=\"p\">,</span> <span class=\"n\">since</span> <span class=\"n\">we</span> <span class=\"n\">are</span> <span class=\"n\">directly</span> <span class=\"n\">using</span> <span class=\"n\">a</span> <span class=\"n\">Sequential</span> <span class=\"n\">model</span> <span class=\"n\">inside</span> <span class=\"n\">a</span> <span class=\"k\">class</span> <span class=\"nc\">that</span> <span class=\"n\">inherits</span> <span class=\"kn\">from</span> <span class=\"err\">`</span><span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"err\">`</span><span class=\"p\">,</span> <span class=\"n\">you</span> <span class=\"n\">don</span><span class=\"s1\">&#39;t actually need a custom `compute_loss` method; instead, you can rely on built-in methods. Here&#39;</span><span class=\"n\">s</span> <span class=\"n\">how</span> <span class=\"n\">you</span> <span class=\"n\">can</span> <span class=\"n\">adjust</span> <span class=\"n\">your</span> <span class=\"n\">code</span><span class=\"p\">:</span>\n",
       "\n",
       "<span class=\"err\">```</span><span class=\"n\">python</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow_recommenders</span> <span class=\"k\">as</span> <span class=\"nn\">tfrs</span>\n",
       "\n",
       "<span class=\"c1\"># Load the dataset</span>\n",
       "<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;final_merged_df.csv&#39;</span><span class=\"p\">)</span>  <span class=\"c1\"># Update to your dataset&#39;s correct path</span>\n",
       "\n",
       "<span class=\"c1\"># Basic preprocessing</span>\n",
       "<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(),</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Action&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Adventure&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Animation&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]</span>\n",
       "<span class=\"n\">df_model</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">features</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>  <span class=\"c1\"># This is where the copy is made to avoid SettingWithCopyWarning</span>\n",
       "\n",
       "<span class=\"c1\"># Normalize continuous features</span>\n",
       "<span class=\"k\">for</span> <span class=\"n\">feature</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">]:</span>\n",
       "    <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span> <span class=\"o\">/</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"c1\"># Split the dataset</span>\n",
       "<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">frac</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Convert to TensorFlow datasets</span>\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)),</span> <span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]))</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)),</span> <span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]))</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">train_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">test_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Model definition</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">MovieRatingModel</span><span class=\"p\">(</span><span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">):</span>  <span class=\"c1\"># Directly inherit from tfrs.Model</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        \n",
       "        <span class=\"c1\"># Rating task</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">tasks</span><span class=\"o\">.</span><span class=\"n\">Ranking</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">MeanSquaredError</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">RootMeanSquaredError</span><span class=\"p\">()]</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">call</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">):</span>\n",
       "        <span class=\"c1\"># We choose to ignore the user features in this model for simplicity&#39;s sake.</span>\n",
       "        <span class=\"n\">movie_embeddings</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span><span class=\"p\">(</span><span class=\"n\">movie_embeddings</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">compute_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">training</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">features</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">rating_predictions</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"c1\"># The task computes the loss and the metrics.</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">predictions</span><span class=\"o\">=</span><span class=\"n\">rating_predictions</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Compile and fit the model</span>\n",
       "<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">MovieRatingModel</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">))</span>\n",
       "\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Evaluate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "<span class=\"err\">```</span>\n",
       "\n",
       "<span class=\"n\">This</span> <span class=\"n\">code</span> <span class=\"n\">corrects</span> <span class=\"n\">the</span> <span class=\"n\">original</span> <span class=\"n\">implementation</span> <span class=\"n\">issues</span><span class=\"p\">:</span>\n",
       "\n",
       "<span class=\"mf\">1.</span> <span class=\"n\">Resolves</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"n\">SettingWithCopyWarning</span><span class=\"err\">`</span> <span class=\"n\">by</span> <span class=\"n\">creating</span> <span class=\"n\">a</span> <span class=\"n\">copy</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">DataFrame</span> <span class=\"nb\">slice</span> <span class=\"k\">with</span> <span class=\"err\">`</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span><span class=\"err\">`</span><span class=\"o\">.</span>\n",
       "<span class=\"mf\">2.</span> <span class=\"n\">Uses</span> <span class=\"n\">directly</span> <span class=\"n\">inherited</span> <span class=\"err\">`</span><span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"err\">`</span> <span class=\"ow\">and</span> <span class=\"n\">implements</span> <span class=\"n\">a</span> <span class=\"err\">`</span><span class=\"n\">compute_loss</span><span class=\"err\">`</span> <span class=\"n\">method</span> <span class=\"n\">that</span> <span class=\"n\">fits</span> <span class=\"ow\">in</span> <span class=\"k\">with</span> <span class=\"n\">the</span> <span class=\"n\">TensorFlow</span> <span class=\"n\">Recommenders</span> <span class=\"n\">Systems</span> <span class=\"p\">(</span><span class=\"n\">TFRS</span><span class=\"p\">)</span> <span class=\"n\">framework</span> <span class=\"n\">logic</span><span class=\"p\">,</span> <span class=\"n\">incorporating</span> <span class=\"n\">the</span> <span class=\"n\">ranking</span> <span class=\"n\">task</span> <span class=\"k\">as</span> <span class=\"n\">part</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">model</span><span class=\"o\">.</span> <span class=\"n\">This</span> <span class=\"n\">approach</span> <span class=\"n\">removes</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"ne\">NotImplementedError</span><span class=\"err\">`</span> <span class=\"n\">caused</span> <span class=\"n\">by</span> <span class=\"n\">the</span> <span class=\"n\">missing</span> <span class=\"err\">`</span><span class=\"n\">compute_loss</span><span class=\"err\">`</span> <span class=\"n\">implementation</span><span class=\"o\">.</span>\n",
       "\n",
       "<span class=\"o\">---</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\n",
       "\\PY{n}{It} \\PY{n}{looks} \\PY{n}{like} \\PY{n}{you}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ve encountered two issues: a `SettingWithCopyWarning` warning from Pandas and a `NotImplementedError` from TensorFlow Recommenders due to the missing implementation of the `compute\\PYZus{}loss` method in the `MovieRatingModel`. Here}\\PY{l+s+s1}{\\PYZsq{}}\\PY{n}{s} \\PY{n}{how} \\PY{n}{you} \\PY{n}{can} \\PY{n}{address} \\PY{n}{both} \\PY{n}{issues}\\PY{p}{:}\n",
       "\n",
       "\\PY{n}{For} \\PY{n}{the} \\PY{n}{Pandas} \\PY{n}{warning}\\PY{p}{,} \\PY{n}{it}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{s best to perform operations on a DataFrame copy to avoid unintentional edits to your original DataFrame or to use the `.loc` method to ensure changes are made explicitly. For the TensorFlow error, you}\\PY{l+s+s1}{\\PYZsq{}}\\PY{n}{ll} \\PY{n}{need} \\PY{n}{to} \\PY{n}{implement} \\PY{n}{the} \\PY{err}{`}\\PY{n}{compute\\PYZus{}loss}\\PY{err}{`} \\PY{n}{method} \\PY{n}{within} \\PY{n}{your} \\PY{n}{model} \\PY{n}{class}\\PY{o}{.} \\PY{n}{However}\\PY{p}{,} \\PY{n}{since} \\PY{n}{we} \\PY{n}{are} \\PY{n}{directly} \\PY{n}{using} \\PY{n}{a} \\PY{n}{Sequential} \\PY{n}{model} \\PY{n}{inside} \\PY{n}{a} \\PY{k}{class} \\PY{n+nc}{that} \\PY{n}{inherits} \\PY{k+kn}{from} \\PY{err}{`}\\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{models}\\PY{o}{.}\\PY{n}{Model}\\PY{err}{`}\\PY{p}{,} \\PY{n}{you} \\PY{n}{don}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{t actually need a custom `compute\\PYZus{}loss` method; instead, you can rely on built\\PYZhy{}in methods. Here}\\PY{l+s+s1}{\\PYZsq{}}\\PY{n}{s} \\PY{n}{how} \\PY{n}{you} \\PY{n}{can} \\PY{n}{adjust} \\PY{n}{your} \\PY{n}{code}\\PY{p}{:}\n",
       "\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\\PY{n}{python}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow} \\PY{k}{as} \\PY{n+nn}{tf}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow\\PYZus{}recommenders} \\PY{k}{as} \\PY{n+nn}{tfrs}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Load the dataset}\n",
       "\\PY{n}{df} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{final\\PYZus{}merged\\PYZus{}df.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} Update to your dataset\\PYZsq{}s correct path}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Basic preprocessing}\n",
       "\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{fillna}\\PY{p}{(}\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Action}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Adventure}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Animation}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n",
       "\\PY{n}{df\\PYZus{}model} \\PY{o}{=} \\PY{n}{df}\\PY{p}{[}\\PY{n}{features}\\PY{p}{]}\\PY{o}{.}\\PY{n}{copy}\\PY{p}{(}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} This is where the copy is made to avoid SettingWithCopyWarning}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Normalize continuous features}\n",
       "\\PY{k}{for} \\PY{n}{feature} \\PY{o+ow}{in} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{:}\n",
       "    \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{=} \\PY{p}{(}\\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{\\PYZhy{}} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)} \\PY{o}{/} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{std}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Split the dataset}\n",
       "\\PY{n}{train} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{sample}\\PY{p}{(}\\PY{n}{frac}\\PY{o}{=}\\PY{l+m+mf}{0.8}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\\PY{n}{test} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{n}{train}\\PY{o}{.}\\PY{n}{index}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Convert to TensorFlow datasets}\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n+nb}{dict}\\PY{p}{(}\\PY{n}{train}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,} \\PY{n}{train}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n+nb}{dict}\\PY{p}{(}\\PY{n}{test}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,} \\PY{n}{test}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{train\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{test\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Model definition}\n",
       "\\PY{k}{class} \\PY{n+nc}{MovieRatingModel}\\PY{p}{(}\\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{Model}\\PY{p}{)}\\PY{p}{:}  \\PY{c+c1}{\\PYZsh{} Directly inherit from tfrs.Model}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \n",
       "        \\PY{c+c1}{\\PYZsh{} Rating task}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task} \\PY{o}{=} \\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{tasks}\\PY{o}{.}\\PY{n}{Ranking}\\PY{p}{(}\n",
       "            \\PY{n}{loss}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{losses}\\PY{o}{.}\\PY{n}{MeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{metrics}\\PY{o}{=}\\PY{p}{[}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{metrics}\\PY{o}{.}\\PY{n}{RootMeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{]}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{call}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} We choose to ignore the user features in this model for simplicity\\PYZsq{}s sake.}\n",
       "        \\PY{n}{movie\\PYZus{}embeddings} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model}\\PY{p}{(}\\PY{n}{movie\\PYZus{}embeddings}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{compute\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{,} \\PY{n}{training}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{labels} \\PY{o}{=} \\PY{n}{features}\\PY{o}{.}\\PY{n}{pop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "        \\PY{n}{rating\\PYZus{}predictions} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} The task computes the loss and the metrics.}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task}\\PY{p}{(}\\PY{n}{labels}\\PY{o}{=}\\PY{n}{labels}\\PY{p}{,} \\PY{n}{predictions}\\PY{o}{=}\\PY{n}{rating\\PYZus{}predictions}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Compile and fit the model}\n",
       "\\PY{n}{model} \\PY{o}{=} \\PY{n}{MovieRatingModel}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{compile}\\PY{p}{(}\\PY{n}{optimizer}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{optimizers}\\PY{o}{.}\\PY{n}{Adam}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.001}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{train\\PYZus{}ds}\\PY{p}{,} \\PY{n}{epochs}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{validation\\PYZus{}data}\\PY{o}{=}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Evaluate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{evaluate}\\PY{p}{(}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\n",
       "\n",
       "\\PY{n}{This} \\PY{n}{code} \\PY{n}{corrects} \\PY{n}{the} \\PY{n}{original} \\PY{n}{implementation} \\PY{n}{issues}\\PY{p}{:}\n",
       "\n",
       "\\PY{l+m+mf}{1.} \\PY{n}{Resolves} \\PY{n}{the} \\PY{err}{`}\\PY{n}{SettingWithCopyWarning}\\PY{err}{`} \\PY{n}{by} \\PY{n}{creating} \\PY{n}{a} \\PY{n}{copy} \\PY{n}{of} \\PY{n}{the} \\PY{n}{DataFrame} \\PY{n+nb}{slice} \\PY{k}{with} \\PY{err}{`}\\PY{o}{.}\\PY{n}{copy}\\PY{p}{(}\\PY{p}{)}\\PY{err}{`}\\PY{o}{.}\n",
       "\\PY{l+m+mf}{2.} \\PY{n}{Uses} \\PY{n}{directly} \\PY{n}{inherited} \\PY{err}{`}\\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{Model}\\PY{err}{`} \\PY{o+ow}{and} \\PY{n}{implements} \\PY{n}{a} \\PY{err}{`}\\PY{n}{compute\\PYZus{}loss}\\PY{err}{`} \\PY{n}{method} \\PY{n}{that} \\PY{n}{fits} \\PY{o+ow}{in} \\PY{k}{with} \\PY{n}{the} \\PY{n}{TensorFlow} \\PY{n}{Recommenders} \\PY{n}{Systems} \\PY{p}{(}\\PY{n}{TFRS}\\PY{p}{)} \\PY{n}{framework} \\PY{n}{logic}\\PY{p}{,} \\PY{n}{incorporating} \\PY{n}{the} \\PY{n}{ranking} \\PY{n}{task} \\PY{k}{as} \\PY{n}{part} \\PY{n}{of} \\PY{n}{the} \\PY{n}{model}\\PY{o}{.} \\PY{n}{This} \\PY{n}{approach} \\PY{n}{removes} \\PY{n}{the} \\PY{err}{`}\\PY{n+ne}{NotImplementedError}\\PY{err}{`} \\PY{n}{caused} \\PY{n}{by} \\PY{n}{the} \\PY{n}{missing} \\PY{err}{`}\\PY{n}{compute\\PYZus{}loss}\\PY{err}{`} \\PY{n}{implementation}\\PY{o}{.}\n",
       "\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "It looks like you've encountered two issues: a `SettingWithCopyWarning` warning from Pandas and a `NotImplementedError` from TensorFlow Recommenders due to the missing implementation of the `compute_loss` method in the `MovieRatingModel`. Here's how you can address both issues:\n",
       "\n",
       "For the Pandas warning, it's best to perform operations on a DataFrame copy to avoid unintentional edits to your original DataFrame or to use the `.loc` method to ensure changes are made explicitly. For the TensorFlow error, you'll need to implement the `compute_loss` method within your model class. However, since we are directly using a Sequential model inside a class that inherits from `tfrs.models.Model`, you don't actually need a custom `compute_loss` method; instead, you can rely on built-in methods. Here's how you can adjust your code:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "import tensorflow as tf\n",
       "import tensorflow_recommenders as tfrs\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('final_merged_df.csv')  # Update to your dataset's correct path\n",
       "\n",
       "# Basic preprocessing\n",
       "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
       "\n",
       "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
       "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
       "\n",
       "# Normalize continuous features\n",
       "for feature in ['duration', 'budget', 'revenue']:\n",
       "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
       "\n",
       "# Split the dataset\n",
       "train = df_model.sample(frac=0.8, random_state=42)\n",
       "test = df_model.drop(train.index)\n",
       "\n",
       "# Convert to TensorFlow datasets\n",
       "train_ds = tf.data.Dataset.from_tensor_slices((dict(train.drop('imdb_score', axis=1)), train['imdb_score']))\n",
       "test_ds = tf.data.Dataset.from_tensor_slices((dict(test.drop('imdb_score', axis=1)), test['imdb_score']))\n",
       "\n",
       "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "\n",
       "# Model definition\n",
       "class MovieRatingModel(tfrs.Model):  # Directly inherit from tfrs.Model\n",
       "\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        self.movie_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(32, activation='relu')\n",
       "        ])\n",
       "        self.rating_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(1)\n",
       "        ])\n",
       "        \n",
       "        # Rating task\n",
       "        self.task = tfrs.tasks.Ranking(\n",
       "            loss=tf.keras.losses.MeanSquaredError(),\n",
       "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
       "        )\n",
       "\n",
       "    def call(self, features):\n",
       "        # We choose to ignore the user features in this model for simplicity's sake.\n",
       "        movie_embeddings = self.movie_model(features)\n",
       "        return self.rating_model(movie_embeddings)\n",
       "\n",
       "    def compute_loss(self, features, training=False):\n",
       "        labels = features.pop('imdb_score')\n",
       "        rating_predictions = self(features)\n",
       "\n",
       "        # The task computes the loss and the metrics.\n",
       "        return self.task(labels=labels, predictions=rating_predictions)\n",
       "\n",
       "# Compile and fit the model\n",
       "model = MovieRatingModel()\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "```\n",
       "\n",
       "This code corrects the original implementation issues:\n",
       "\n",
       "1. Resolves the `SettingWithCopyWarning` by creating a copy of the DataFrame slice with `.copy()`.\n",
       "2. Uses directly inherited `tfrs.Model` and implements a `compute_loss` method that fits in with the TensorFlow Recommenders Systems (TFRS) framework logic, incorporating the ranking task as part of the model. This approach removes the `NotImplementedError` caused by the missing `compute_loss` implementation.\n",
       "\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using prompt_error to define a prompt to resolve the error encountered\n",
    "prompt2 = prompt_error(prev_response, err)\n",
    "msg_2 = get_resp_oai(prompt2,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_2, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e295faff-2d3a-41ad-ba55-2bee4795968b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"o\">---</span>\n",
       "\n",
       "<span class=\"err\">```</span><span class=\"n\">python</span>\n",
       "<span class=\"c1\"># It looks like you&#39;ve encountered two issues: a `SettingWithCopyWarning` warning from Pandas and a `NotImplementedError` from TensorFlow Recommenders </span>\n",
       "<span class=\"c1\"># due to the missing implementation of the `compute_loss` method in the `MovieRatingModel`. Here&#39;s how you can address both issues:</span>\n",
       "<span class=\"c1\"># </span>\n",
       "<span class=\"c1\"># For the Pandas warning, it&#39;s best to perform operations on a DataFrame copy to avoid unintentional edits to your original DataFrame or </span>\n",
       "<span class=\"c1\"># to use the `.loc` method to ensure changes are made explicitly. For the TensorFlow error, you&#39;ll need to implement the `compute_loss` method </span>\n",
       "<span class=\"c1\"># within your model class. However, since we are directly using a Sequential model inside a class that inherits from `tfrs.models.Model`, </span>\n",
       "<span class=\"c1\"># you don&#39;t actually need a custom `compute_loss` method; instead, you can rely on built-in methods. Here&#39;s how you can adjust your code:</span>\n",
       "\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow_recommenders</span> <span class=\"k\">as</span> <span class=\"nn\">tfrs</span>\n",
       "\n",
       "<span class=\"c1\"># Load the dataset</span>\n",
       "<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;final_merged_df.csv&#39;</span><span class=\"p\">)</span>  <span class=\"c1\"># Update to your dataset&#39;s correct path</span>\n",
       "\n",
       "<span class=\"c1\"># Basic preprocessing</span>\n",
       "<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(),</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Action&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Adventure&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Animation&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]</span>\n",
       "<span class=\"n\">df_model</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">features</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>  <span class=\"c1\"># This is where the copy is made to avoid SettingWithCopyWarning</span>\n",
       "\n",
       "<span class=\"c1\"># Normalize continuous features</span>\n",
       "<span class=\"k\">for</span> <span class=\"n\">feature</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">]:</span>\n",
       "    <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span> <span class=\"o\">/</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"c1\"># Split the dataset</span>\n",
       "<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">frac</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Convert to TensorFlow datasets</span>\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)),</span> <span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]))</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)),</span> <span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]))</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">train_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">test_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Model definition</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">MovieRatingModel</span><span class=\"p\">(</span><span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">):</span>  <span class=\"c1\"># Directly inherit from tfrs.Model</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        \n",
       "        <span class=\"c1\"># Rating task</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">tasks</span><span class=\"o\">.</span><span class=\"n\">Ranking</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">MeanSquaredError</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">RootMeanSquaredError</span><span class=\"p\">()]</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">call</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">):</span>\n",
       "        <span class=\"c1\"># We choose to ignore the user features in this model for simplicity&#39;s sake.</span>\n",
       "        <span class=\"n\">movie_embeddings</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span><span class=\"p\">(</span><span class=\"n\">movie_embeddings</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">compute_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">training</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">features</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">rating_predictions</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"c1\"># The task computes the loss and the metrics.</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">predictions</span><span class=\"o\">=</span><span class=\"n\">rating_predictions</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Compile and fit the model</span>\n",
       "<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">MovieRatingModel</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">))</span>\n",
       "\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Evaluate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># This code corrects the original implementation issues:</span>\n",
       "<span class=\"c1\"># 1. Resolves the `SettingWithCopyWarning` by creating a copy of the DataFrame slice with `.copy()`.</span>\n",
       "<span class=\"c1\"># 2. Uses directly inherited `tfrs.Model` and implements a `compute_loss` method that fits in with the TensorFlow Recommenders Systems (TFRS) framework logic, </span>\n",
       "<span class=\"c1\"># incorporating the ranking task as part of the model. This approach removes the `NotImplementedError` caused by the missing `compute_loss` implementation.</span>\n",
       "<span class=\"err\">```</span>\n",
       "\n",
       "<span class=\"o\">---</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\\PY{n}{python}\n",
       "\\PY{c+c1}{\\PYZsh{} It looks like you\\PYZsq{}ve encountered two issues: a `SettingWithCopyWarning` warning from Pandas and a `NotImplementedError` from TensorFlow Recommenders }\n",
       "\\PY{c+c1}{\\PYZsh{} due to the missing implementation of the `compute\\PYZus{}loss` method in the `MovieRatingModel`. Here\\PYZsq{}s how you can address both issues:}\n",
       "\\PY{c+c1}{\\PYZsh{} }\n",
       "\\PY{c+c1}{\\PYZsh{} For the Pandas warning, it\\PYZsq{}s best to perform operations on a DataFrame copy to avoid unintentional edits to your original DataFrame or }\n",
       "\\PY{c+c1}{\\PYZsh{} to use the `.loc` method to ensure changes are made explicitly. For the TensorFlow error, you\\PYZsq{}ll need to implement the `compute\\PYZus{}loss` method }\n",
       "\\PY{c+c1}{\\PYZsh{} within your model class. However, since we are directly using a Sequential model inside a class that inherits from `tfrs.models.Model`, }\n",
       "\\PY{c+c1}{\\PYZsh{} you don\\PYZsq{}t actually need a custom `compute\\PYZus{}loss` method; instead, you can rely on built\\PYZhy{}in methods. Here\\PYZsq{}s how you can adjust your code:}\n",
       "\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow} \\PY{k}{as} \\PY{n+nn}{tf}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow\\PYZus{}recommenders} \\PY{k}{as} \\PY{n+nn}{tfrs}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Load the dataset}\n",
       "\\PY{n}{df} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{final\\PYZus{}merged\\PYZus{}df.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} Update to your dataset\\PYZsq{}s correct path}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Basic preprocessing}\n",
       "\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{fillna}\\PY{p}{(}\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Action}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Adventure}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Animation}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n",
       "\\PY{n}{df\\PYZus{}model} \\PY{o}{=} \\PY{n}{df}\\PY{p}{[}\\PY{n}{features}\\PY{p}{]}\\PY{o}{.}\\PY{n}{copy}\\PY{p}{(}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} This is where the copy is made to avoid SettingWithCopyWarning}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Normalize continuous features}\n",
       "\\PY{k}{for} \\PY{n}{feature} \\PY{o+ow}{in} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{:}\n",
       "    \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{=} \\PY{p}{(}\\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{\\PYZhy{}} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)} \\PY{o}{/} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{std}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Split the dataset}\n",
       "\\PY{n}{train} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{sample}\\PY{p}{(}\\PY{n}{frac}\\PY{o}{=}\\PY{l+m+mf}{0.8}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\\PY{n}{test} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{n}{train}\\PY{o}{.}\\PY{n}{index}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Convert to TensorFlow datasets}\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n+nb}{dict}\\PY{p}{(}\\PY{n}{train}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,} \\PY{n}{train}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n+nb}{dict}\\PY{p}{(}\\PY{n}{test}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,} \\PY{n}{test}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{train\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{test\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Model definition}\n",
       "\\PY{k}{class} \\PY{n+nc}{MovieRatingModel}\\PY{p}{(}\\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{Model}\\PY{p}{)}\\PY{p}{:}  \\PY{c+c1}{\\PYZsh{} Directly inherit from tfrs.Model}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \n",
       "        \\PY{c+c1}{\\PYZsh{} Rating task}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task} \\PY{o}{=} \\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{tasks}\\PY{o}{.}\\PY{n}{Ranking}\\PY{p}{(}\n",
       "            \\PY{n}{loss}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{losses}\\PY{o}{.}\\PY{n}{MeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{metrics}\\PY{o}{=}\\PY{p}{[}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{metrics}\\PY{o}{.}\\PY{n}{RootMeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{]}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{call}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} We choose to ignore the user features in this model for simplicity\\PYZsq{}s sake.}\n",
       "        \\PY{n}{movie\\PYZus{}embeddings} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model}\\PY{p}{(}\\PY{n}{movie\\PYZus{}embeddings}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{compute\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{,} \\PY{n}{training}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{labels} \\PY{o}{=} \\PY{n}{features}\\PY{o}{.}\\PY{n}{pop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "        \\PY{n}{rating\\PYZus{}predictions} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} The task computes the loss and the metrics.}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task}\\PY{p}{(}\\PY{n}{labels}\\PY{o}{=}\\PY{n}{labels}\\PY{p}{,} \\PY{n}{predictions}\\PY{o}{=}\\PY{n}{rating\\PYZus{}predictions}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Compile and fit the model}\n",
       "\\PY{n}{model} \\PY{o}{=} \\PY{n}{MovieRatingModel}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{compile}\\PY{p}{(}\\PY{n}{optimizer}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{optimizers}\\PY{o}{.}\\PY{n}{Adam}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.001}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{train\\PYZus{}ds}\\PY{p}{,} \\PY{n}{epochs}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{validation\\PYZus{}data}\\PY{o}{=}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Evaluate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{evaluate}\\PY{p}{(}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} This code corrects the original implementation issues:}\n",
       "\\PY{c+c1}{\\PYZsh{} 1. Resolves the `SettingWithCopyWarning` by creating a copy of the DataFrame slice with `.copy()`.}\n",
       "\\PY{c+c1}{\\PYZsh{} 2. Uses directly inherited `tfrs.Model` and implements a `compute\\PYZus{}loss` method that fits in with the TensorFlow Recommenders Systems (TFRS) framework logic, }\n",
       "\\PY{c+c1}{\\PYZsh{} incorporating the ranking task as part of the model. This approach removes the `NotImplementedError` caused by the missing `compute\\PYZus{}loss` implementation.}\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\n",
       "\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "```python\n",
       "# It looks like you've encountered two issues: a `SettingWithCopyWarning` warning from Pandas and a `NotImplementedError` from TensorFlow Recommenders \n",
       "# due to the missing implementation of the `compute_loss` method in the `MovieRatingModel`. Here's how you can address both issues:\n",
       "# \n",
       "# For the Pandas warning, it's best to perform operations on a DataFrame copy to avoid unintentional edits to your original DataFrame or \n",
       "# to use the `.loc` method to ensure changes are made explicitly. For the TensorFlow error, you'll need to implement the `compute_loss` method \n",
       "# within your model class. However, since we are directly using a Sequential model inside a class that inherits from `tfrs.models.Model`, \n",
       "# you don't actually need a custom `compute_loss` method; instead, you can rely on built-in methods. Here's how you can adjust your code:\n",
       "\n",
       "import pandas as pd\n",
       "import tensorflow as tf\n",
       "import tensorflow_recommenders as tfrs\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('final_merged_df.csv')  # Update to your dataset's correct path\n",
       "\n",
       "# Basic preprocessing\n",
       "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
       "\n",
       "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
       "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
       "\n",
       "# Normalize continuous features\n",
       "for feature in ['duration', 'budget', 'revenue']:\n",
       "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
       "\n",
       "# Split the dataset\n",
       "train = df_model.sample(frac=0.8, random_state=42)\n",
       "test = df_model.drop(train.index)\n",
       "\n",
       "# Convert to TensorFlow datasets\n",
       "train_ds = tf.data.Dataset.from_tensor_slices((dict(train.drop('imdb_score', axis=1)), train['imdb_score']))\n",
       "test_ds = tf.data.Dataset.from_tensor_slices((dict(test.drop('imdb_score', axis=1)), test['imdb_score']))\n",
       "\n",
       "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "\n",
       "# Model definition\n",
       "class MovieRatingModel(tfrs.Model):  # Directly inherit from tfrs.Model\n",
       "\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        self.movie_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(32, activation='relu')\n",
       "        ])\n",
       "        self.rating_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(1)\n",
       "        ])\n",
       "        \n",
       "        # Rating task\n",
       "        self.task = tfrs.tasks.Ranking(\n",
       "            loss=tf.keras.losses.MeanSquaredError(),\n",
       "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
       "        )\n",
       "\n",
       "    def call(self, features):\n",
       "        # We choose to ignore the user features in this model for simplicity's sake.\n",
       "        movie_embeddings = self.movie_model(features)\n",
       "        return self.rating_model(movie_embeddings)\n",
       "\n",
       "    def compute_loss(self, features, training=False):\n",
       "        labels = features.pop('imdb_score')\n",
       "        rating_predictions = self(features)\n",
       "\n",
       "        # The task computes the loss and the metrics.\n",
       "        return self.task(labels=labels, predictions=rating_predictions)\n",
       "\n",
       "# Compile and fit the model\n",
       "model = MovieRatingModel()\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "\n",
       "# This code corrects the original implementation issues:\n",
       "# 1. Resolves the `SettingWithCopyWarning` by creating a copy of the DataFrame slice with `.copy()`.\n",
       "# 2. Uses directly inherited `tfrs.Model` and implements a `compute_loss` method that fits in with the TensorFlow Recommenders Systems (TFRS) framework logic, \n",
       "# incorporating the ranking task as part of the model. This approach removes the `NotImplementedError` caused by the missing `compute_loss` implementation.\n",
       "```\n",
       "\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt3 = helper_extraction_prompt(msg_2)\n",
    "msg_3 = get_resp_oai(prompt3,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_3, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1693afa4-551e-4925-9ef7-36388fc1065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"<string>\", line 63, in compute_loss\n        \n\n    AttributeError: 'tuple' object has no attribute 'pop'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg_3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m---\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m```python\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmsg_3\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m```\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m---\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:73\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filejo7rd7xr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 68\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;66;03m# Handle regularization losses as well.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m   regularization_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "File \u001b[0;32m<string>:63\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(self, features, training)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"<string>\", line 63, in compute_loss\n        \n\n    AttributeError: 'tuple' object has no attribute 'pop'\n"
     ]
    }
   ],
   "source": [
    "exec(msg_3[len(\"---\\n\\n```python\\n\"):len(msg_3)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f41dcfd-6be1-42b7-9bf0-2e8f063c71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = \"\"\" \n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "Cell In[75], line 1\n",
    "----> 1 exec(msg_3[len(\"---\\n\\n```python\\n\"):len(msg_3)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "File <string>:73\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n",
    "     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "     68     # To get the full stack trace, call:\n",
    "     69     # `tf.debugging.disable_traceback_filtering()`\n",
    "---> 70     raise e.with_traceback(filtered_tb) from None\n",
    "     71 finally:\n",
    "     72     del filtered_tb\n",
    "\n",
    "File /tmp/__autograph_generated_filejo7rd7xr.py:15, in outer_factory.<locals>.inner_factory.<locals>.tf__train_function(iterator)\n",
    "     13 try:\n",
    "     14     do_return = True\n",
    "---> 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
    "     16 except:\n",
    "     17     do_return = False\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py:68, in Model.train_step(self, inputs)\n",
    "     65 Custom train step using the `compute_loss` method.\n",
    "     67 with tf.GradientTape() as tape:\n",
    "---> 68   loss = self.compute_loss(inputs, training=True)\n",
    "     70   # Handle regularization losses as well.\n",
    "     71   regularization_loss = sum(self.losses)\n",
    "\n",
    "File <string>:63, in compute_loss(self, features, training)\n",
    "\n",
    "AttributeError: in user code:\n",
    "\n",
    "    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n",
    "        return step_function(self, iterator)\n",
    "    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n",
    "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
    "    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n",
    "        outputs = model.train_step(data)\n",
    "    File \"/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n",
    "        loss = self.compute_loss(inputs, training=True)\n",
    "    File \"<string>\", line 63, in compute_loss\n",
    "        \n",
    "\n",
    "    AttributeError: 'tuple' object has no attribute 'pop' \n",
    "\"\"\"\n",
    "prev_response = \"\"\"\n",
    "# It looks like you've encountered two issues: a `SettingWithCopyWarning` warning from Pandas and a `NotImplementedError` from TensorFlow Recommenders \n",
    "# due to the missing implementation of the `compute_loss` method in the `MovieRatingModel`. Here's how you can address both issues:\n",
    "# \n",
    "# For the Pandas warning, it's best to perform operations on a DataFrame copy to avoid unintentional edits to your original DataFrame or \n",
    "# to use the `.loc` method to ensure changes are made explicitly. For the TensorFlow error, you'll need to implement the `compute_loss` method \n",
    "# within your model class. However, since we are directly using a Sequential model inside a class that inherits from `tfrs.models.Model`, \n",
    "# you don't actually need a custom `compute_loss` method; instead, you can rely on built-in methods. Here's how you can adjust your code:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('final_merged_df.csv')  # Update to your dataset's correct path\n",
    "\n",
    "# Basic preprocessing\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "\n",
    "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((dict(train.drop('imdb_score', axis=1)), train['imdb_score']))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((dict(test.drop('imdb_score', axis=1)), test['imdb_score']))\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Model definition\n",
    "class MovieRatingModel(tfrs.Model):  # Directly inherit from tfrs.Model\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(64, activation='relu'),\n",
    "          tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(64, activation='relu'),\n",
    "          tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        # Rating task\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        # We choose to ignore the user features in this model for simplicity's sake.\n",
    "        movie_embeddings = self.movie_model(features)\n",
    "        return self.rating_model(movie_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        labels = features.pop('imdb_score')\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "# Compile and fit the model\n",
    "model = MovieRatingModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
    "\n",
    "# Evaluate\n",
    "model.evaluate(test_ds)\n",
    "\n",
    "# This code corrects the original implementation issues:\n",
    "# 1. Resolves the `SettingWithCopyWarning` by creating a copy of the DataFrame slice with `.copy()`.\n",
    "# 2. Uses directly inherited `tfrs.Model` and implements a `compute_loss` method that fits in with the TensorFlow Recommenders Systems (TFRS) framework logic, \n",
    "# incorporating the ranking task as part of the model. This approach removes the `NotImplementedError` caused by the missing `compute_loss` implementation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "783853da-4a14-4246-b548-258a31e0df58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"o\">---</span>\n",
       "\n",
       "<span class=\"n\">It</span> <span class=\"n\">seems</span> <span class=\"n\">the</span> <span class=\"n\">issue</span> <span class=\"n\">arises</span> <span class=\"kn\">from</span> <span class=\"nn\">how</span> <span class=\"n\">the</span> <span class=\"n\">data</span> <span class=\"ow\">is</span> <span class=\"n\">passed</span> <span class=\"n\">to</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"n\">compute_loss</span><span class=\"err\">`</span> <span class=\"n\">method</span><span class=\"o\">.</span> <span class=\"n\">The</span> <span class=\"n\">error</span> <span class=\"n\">message</span> <span class=\"n\">you</span> <span class=\"n\">shared</span> <span class=\"n\">suggests</span> <span class=\"n\">that</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"n\">features</span><span class=\"err\">`</span> <span class=\"n\">variable</span><span class=\"p\">,</span> <span class=\"n\">expected</span> <span class=\"n\">to</span> <span class=\"n\">be</span> <span class=\"n\">a</span> <span class=\"n\">dictionary</span> <span class=\"ow\">or</span> <span class=\"n\">a</span> <span class=\"n\">similar</span> <span class=\"nb\">object</span> <span class=\"kn\">from</span> <span class=\"nn\">which</span> <span class=\"n\">you</span> <span class=\"n\">can</span> <span class=\"err\">`</span><span class=\"n\">pop</span><span class=\"err\">`</span> <span class=\"n\">the</span> <span class=\"s1\">&#39;imdb_score&#39;</span> <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"ow\">is</span> <span class=\"n\">actually</span> <span class=\"n\">being</span> <span class=\"n\">received</span> <span class=\"k\">as</span> <span class=\"n\">a</span> <span class=\"nb\">tuple</span><span class=\"o\">.</span> <span class=\"n\">This</span> <span class=\"n\">mismatch</span> <span class=\"n\">typically</span> <span class=\"n\">happens</span> <span class=\"n\">when</span> <span class=\"n\">the</span> <span class=\"n\">dataset</span> <span class=\"n\">provided</span> <span class=\"n\">to</span> <span class=\"n\">the</span> <span class=\"n\">TensorFlow</span> <span class=\"n\">model</span> <span class=\"n\">does</span> <span class=\"ow\">not</span> <span class=\"n\">match</span> <span class=\"n\">the</span> <span class=\"n\">expected</span> <span class=\"n\">shape</span> <span class=\"ow\">or</span> <span class=\"n\">structure</span><span class=\"o\">.</span>\n",
       "\n",
       "<span class=\"n\">Let</span><span class=\"s1\">&#39;s adjust the code to ensure the data is prepared correctly for the model. We&#39;</span><span class=\"n\">ll</span> <span class=\"n\">update</span> <span class=\"n\">the</span> <span class=\"n\">way</span> <span class=\"n\">the</span> <span class=\"n\">dataset</span> <span class=\"ow\">is</span> <span class=\"n\">created</span> <span class=\"n\">to</span> <span class=\"n\">explicitly</span> <span class=\"n\">define</span> <span class=\"n\">a</span> <span class=\"n\">structure</span> <span class=\"n\">that</span> <span class=\"n\">separates</span> <span class=\"n\">the</span> <span class=\"n\">features</span> <span class=\"kn\">from</span> <span class=\"nn\">the</span> <span class=\"n\">labels</span> <span class=\"n\">right</span> <span class=\"n\">before</span> <span class=\"n\">they</span> <span class=\"n\">are</span> <span class=\"n\">batched</span><span class=\"o\">.</span> <span class=\"n\">This</span> <span class=\"n\">structure</span> <span class=\"n\">will</span> <span class=\"n\">prevent</span> <span class=\"n\">the</span> <span class=\"nb\">tuple</span> <span class=\"n\">issue</span> <span class=\"n\">when</span> <span class=\"n\">accessing</span> <span class=\"n\">the</span> <span class=\"n\">data</span> <span class=\"ow\">in</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"n\">compute_loss</span><span class=\"err\">`</span> <span class=\"n\">method</span><span class=\"p\">:</span>\n",
       "\n",
       "<span class=\"err\">```</span><span class=\"n\">python</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow_recommenders</span> <span class=\"k\">as</span> <span class=\"nn\">tfrs</span>\n",
       "\n",
       "<span class=\"c1\"># Load the dataset</span>\n",
       "<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;final_merged_df.csv&#39;</span><span class=\"p\">)</span>  <span class=\"c1\"># Update to your dataset&#39;s correct path</span>\n",
       "\n",
       "<span class=\"c1\"># Basic preprocessing</span>\n",
       "<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(),</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Action&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Adventure&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Animation&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]</span>\n",
       "<span class=\"n\">df_model</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">features</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>  <span class=\"c1\"># This is where the copy is made to avoid SettingWithCopyWarning</span>\n",
       "\n",
       "<span class=\"c1\"># Normalize continuous features</span>\n",
       "<span class=\"k\">for</span> <span class=\"n\">feature</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">]:</span>\n",
       "    <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span> <span class=\"o\">/</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"c1\"># Split the dataset</span>\n",
       "<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">frac</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Correctly structure the dataset for TensorFlow</span>\n",
       "<span class=\"k\">def</span> <span class=\"nf\">map_func</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span>\n",
       "\n",
       "<span class=\"n\">train_features</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"ow\">in</span> <span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<span class=\"n\">train_labels</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">])</span>\n",
       "<span class=\"n\">test_features</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"ow\">in</span> <span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<span class=\"n\">test_labels</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">])</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"n\">train_features</span><span class=\"p\">,</span> <span class=\"n\">train_labels</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">map_func</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"n\">test_features</span><span class=\"p\">,</span> <span class=\"n\">test_labels</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">map_func</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">train_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">test_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Model definition remains the same</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">MovieRatingModel</span><span class=\"p\">(</span><span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">):</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">tasks</span><span class=\"o\">.</span><span class=\"n\">Ranking</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">MeanSquaredError</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">RootMeanSquaredError</span><span class=\"p\">()]</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">call</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">movie_embeddings</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span><span class=\"p\">(</span><span class=\"n\">movie_embeddings</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">compute_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">training</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
       "        <span class=\"c1\"># Adjusted to expect a tuple as input</span>\n",
       "        <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">features</span>  <span class=\"c1\"># Unpack the tuple</span>\n",
       "        <span class=\"n\">rating_predictions</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">call</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">predictions</span><span class=\"o\">=</span><span class=\"n\">rating_predictions</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Compile and fit the model</span>\n",
       "<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">MovieRatingModel</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">))</span>\n",
       "\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Evaluate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "<span class=\"err\">```</span>\n",
       "\n",
       "<span class=\"n\">This</span> <span class=\"n\">modification</span> <span class=\"n\">ensures</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"n\">train_ds</span><span class=\"err\">`</span> <span class=\"ow\">and</span> <span class=\"err\">`</span><span class=\"n\">test_ds</span><span class=\"err\">`</span> <span class=\"n\">datasets</span> <span class=\"n\">are</span> <span class=\"n\">structured</span> <span class=\"n\">correctly</span><span class=\"p\">,</span> <span class=\"n\">addressing</span> <span class=\"n\">the</span> <span class=\"n\">root</span> <span class=\"n\">cause</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"ne\">AttributeError</span> <span class=\"n\">you</span> <span class=\"n\">encountered</span><span class=\"o\">.</span> <span class=\"n\">By</span> <span class=\"n\">mapping</span> <span class=\"n\">the</span> <span class=\"n\">dataset</span> <span class=\"n\">into</span> <span class=\"n\">the</span> <span class=\"n\">correct</span> <span class=\"nb\">format</span> <span class=\"err\">`</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span><span class=\"err\">`</span> <span class=\"n\">before</span> <span class=\"n\">batching</span><span class=\"p\">,</span> <span class=\"n\">we</span> <span class=\"n\">ensure</span> <span class=\"n\">that</span> <span class=\"n\">the</span> <span class=\"n\">model</span> <span class=\"n\">receives</span> <span class=\"n\">the</span> <span class=\"nb\">input</span> <span class=\"ow\">in</span> <span class=\"n\">the</span> <span class=\"n\">expected</span> <span class=\"n\">structure</span><span class=\"p\">,</span> <span class=\"n\">allowing</span> <span class=\"n\">the</span> <span class=\"err\">`</span><span class=\"n\">compute_loss</span><span class=\"err\">`</span> <span class=\"n\">method</span> <span class=\"n\">to</span> <span class=\"n\">work</span> <span class=\"k\">as</span> <span class=\"n\">intended</span><span class=\"o\">.</span>\n",
       "\n",
       "<span class=\"o\">---</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\n",
       "\\PY{n}{It} \\PY{n}{seems} \\PY{n}{the} \\PY{n}{issue} \\PY{n}{arises} \\PY{k+kn}{from} \\PY{n+nn}{how} \\PY{n}{the} \\PY{n}{data} \\PY{o+ow}{is} \\PY{n}{passed} \\PY{n}{to} \\PY{n}{the} \\PY{err}{`}\\PY{n}{compute\\PYZus{}loss}\\PY{err}{`} \\PY{n}{method}\\PY{o}{.} \\PY{n}{The} \\PY{n}{error} \\PY{n}{message} \\PY{n}{you} \\PY{n}{shared} \\PY{n}{suggests} \\PY{n}{that} \\PY{n}{the} \\PY{err}{`}\\PY{n}{features}\\PY{err}{`} \\PY{n}{variable}\\PY{p}{,} \\PY{n}{expected} \\PY{n}{to} \\PY{n}{be} \\PY{n}{a} \\PY{n}{dictionary} \\PY{o+ow}{or} \\PY{n}{a} \\PY{n}{similar} \\PY{n+nb}{object} \\PY{k+kn}{from} \\PY{n+nn}{which} \\PY{n}{you} \\PY{n}{can} \\PY{err}{`}\\PY{n}{pop}\\PY{err}{`} \\PY{n}{the} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}} \\PY{n}{key}\\PY{p}{,} \\PY{o+ow}{is} \\PY{n}{actually} \\PY{n}{being} \\PY{n}{received} \\PY{k}{as} \\PY{n}{a} \\PY{n+nb}{tuple}\\PY{o}{.} \\PY{n}{This} \\PY{n}{mismatch} \\PY{n}{typically} \\PY{n}{happens} \\PY{n}{when} \\PY{n}{the} \\PY{n}{dataset} \\PY{n}{provided} \\PY{n}{to} \\PY{n}{the} \\PY{n}{TensorFlow} \\PY{n}{model} \\PY{n}{does} \\PY{o+ow}{not} \\PY{n}{match} \\PY{n}{the} \\PY{n}{expected} \\PY{n}{shape} \\PY{o+ow}{or} \\PY{n}{structure}\\PY{o}{.}\n",
       "\n",
       "\\PY{n}{Let}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{s adjust the code to ensure the data is prepared correctly for the model. We}\\PY{l+s+s1}{\\PYZsq{}}\\PY{n}{ll} \\PY{n}{update} \\PY{n}{the} \\PY{n}{way} \\PY{n}{the} \\PY{n}{dataset} \\PY{o+ow}{is} \\PY{n}{created} \\PY{n}{to} \\PY{n}{explicitly} \\PY{n}{define} \\PY{n}{a} \\PY{n}{structure} \\PY{n}{that} \\PY{n}{separates} \\PY{n}{the} \\PY{n}{features} \\PY{k+kn}{from} \\PY{n+nn}{the} \\PY{n}{labels} \\PY{n}{right} \\PY{n}{before} \\PY{n}{they} \\PY{n}{are} \\PY{n}{batched}\\PY{o}{.} \\PY{n}{This} \\PY{n}{structure} \\PY{n}{will} \\PY{n}{prevent} \\PY{n}{the} \\PY{n+nb}{tuple} \\PY{n}{issue} \\PY{n}{when} \\PY{n}{accessing} \\PY{n}{the} \\PY{n}{data} \\PY{o+ow}{in} \\PY{n}{the} \\PY{err}{`}\\PY{n}{compute\\PYZus{}loss}\\PY{err}{`} \\PY{n}{method}\\PY{p}{:}\n",
       "\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\\PY{n}{python}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow} \\PY{k}{as} \\PY{n+nn}{tf}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow\\PYZus{}recommenders} \\PY{k}{as} \\PY{n+nn}{tfrs}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Load the dataset}\n",
       "\\PY{n}{df} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{final\\PYZus{}merged\\PYZus{}df.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} Update to your dataset\\PYZsq{}s correct path}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Basic preprocessing}\n",
       "\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{fillna}\\PY{p}{(}\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Action}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Adventure}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Animation}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n",
       "\\PY{n}{df\\PYZus{}model} \\PY{o}{=} \\PY{n}{df}\\PY{p}{[}\\PY{n}{features}\\PY{p}{]}\\PY{o}{.}\\PY{n}{copy}\\PY{p}{(}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} This is where the copy is made to avoid SettingWithCopyWarning}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Normalize continuous features}\n",
       "\\PY{k}{for} \\PY{n}{feature} \\PY{o+ow}{in} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{:}\n",
       "    \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{=} \\PY{p}{(}\\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{\\PYZhy{}} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)} \\PY{o}{/} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{std}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Split the dataset}\n",
       "\\PY{n}{train} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{sample}\\PY{p}{(}\\PY{n}{frac}\\PY{o}{=}\\PY{l+m+mf}{0.8}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\\PY{n}{test} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{n}{train}\\PY{o}{.}\\PY{n}{index}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Correctly structure the dataset for TensorFlow}\n",
       "\\PY{k}{def} \\PY{n+nf}{map\\PYZus{}func}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{label}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{return} \\PY{n}{features}\\PY{p}{,} \\PY{n}{label}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}features} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{n}{name}\\PY{p}{:} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{value}\\PY{p}{)} \\PY{k}{for} \\PY{n}{name}\\PY{p}{,} \\PY{n}{value} \\PY{o+ow}{in} \\PY{n}{train}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\n",
       "\\PY{n}{train\\PYZus{}labels} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{train}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}features} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{n}{name}\\PY{p}{:} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{value}\\PY{p}{)} \\PY{k}{for} \\PY{n}{name}\\PY{p}{,} \\PY{n}{value} \\PY{o+ow}{in} \\PY{n}{test}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\n",
       "\\PY{n}{test\\PYZus{}labels} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{test}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n}{train\\PYZus{}features}\\PY{p}{,} \\PY{n}{train\\PYZus{}labels}\\PY{p}{)}\\PY{p}{)}\\PY{o}{.}\\PY{n}{map}\\PY{p}{(}\\PY{n}{map\\PYZus{}func}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n}{test\\PYZus{}features}\\PY{p}{,} \\PY{n}{test\\PYZus{}labels}\\PY{p}{)}\\PY{p}{)}\\PY{o}{.}\\PY{n}{map}\\PY{p}{(}\\PY{n}{map\\PYZus{}func}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{train\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{test\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Model definition remains the same}\n",
       "\\PY{k}{class} \\PY{n+nc}{MovieRatingModel}\\PY{p}{(}\\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{Model}\\PY{p}{)}\\PY{p}{:}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task} \\PY{o}{=} \\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{tasks}\\PY{o}{.}\\PY{n}{Ranking}\\PY{p}{(}\n",
       "            \\PY{n}{loss}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{losses}\\PY{o}{.}\\PY{n}{MeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{metrics}\\PY{o}{=}\\PY{p}{[}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{metrics}\\PY{o}{.}\\PY{n}{RootMeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{]}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{call}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{movie\\PYZus{}embeddings} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model}\\PY{p}{(}\\PY{n}{movie\\PYZus{}embeddings}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{compute\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{,} \\PY{n}{training}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} Adjusted to expect a tuple as input}\n",
       "        \\PY{n}{features}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{features}  \\PY{c+c1}{\\PYZsh{} Unpack the tuple}\n",
       "        \\PY{n}{rating\\PYZus{}predictions} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{call}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task}\\PY{p}{(}\\PY{n}{labels}\\PY{o}{=}\\PY{n}{labels}\\PY{p}{,} \\PY{n}{predictions}\\PY{o}{=}\\PY{n}{rating\\PYZus{}predictions}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Compile and fit the model}\n",
       "\\PY{n}{model} \\PY{o}{=} \\PY{n}{MovieRatingModel}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{compile}\\PY{p}{(}\\PY{n}{optimizer}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{optimizers}\\PY{o}{.}\\PY{n}{Adam}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.001}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{train\\PYZus{}ds}\\PY{p}{,} \\PY{n}{epochs}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{validation\\PYZus{}data}\\PY{o}{=}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Evaluate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{evaluate}\\PY{p}{(}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\n",
       "\n",
       "\\PY{n}{This} \\PY{n}{modification} \\PY{n}{ensures} \\PY{n}{the} \\PY{err}{`}\\PY{n}{train\\PYZus{}ds}\\PY{err}{`} \\PY{o+ow}{and} \\PY{err}{`}\\PY{n}{test\\PYZus{}ds}\\PY{err}{`} \\PY{n}{datasets} \\PY{n}{are} \\PY{n}{structured} \\PY{n}{correctly}\\PY{p}{,} \\PY{n}{addressing} \\PY{n}{the} \\PY{n}{root} \\PY{n}{cause} \\PY{n}{of} \\PY{n}{the} \\PY{n+ne}{AttributeError} \\PY{n}{you} \\PY{n}{encountered}\\PY{o}{.} \\PY{n}{By} \\PY{n}{mapping} \\PY{n}{the} \\PY{n}{dataset} \\PY{n}{into} \\PY{n}{the} \\PY{n}{correct} \\PY{n+nb}{format} \\PY{err}{`}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{labels}\\PY{p}{)}\\PY{err}{`} \\PY{n}{before} \\PY{n}{batching}\\PY{p}{,} \\PY{n}{we} \\PY{n}{ensure} \\PY{n}{that} \\PY{n}{the} \\PY{n}{model} \\PY{n}{receives} \\PY{n}{the} \\PY{n+nb}{input} \\PY{o+ow}{in} \\PY{n}{the} \\PY{n}{expected} \\PY{n}{structure}\\PY{p}{,} \\PY{n}{allowing} \\PY{n}{the} \\PY{err}{`}\\PY{n}{compute\\PYZus{}loss}\\PY{err}{`} \\PY{n}{method} \\PY{n}{to} \\PY{n}{work} \\PY{k}{as} \\PY{n}{intended}\\PY{o}{.}\n",
       "\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "It seems the issue arises from how the data is passed to the `compute_loss` method. The error message you shared suggests that the `features` variable, expected to be a dictionary or a similar object from which you can `pop` the 'imdb_score' key, is actually being received as a tuple. This mismatch typically happens when the dataset provided to the TensorFlow model does not match the expected shape or structure.\n",
       "\n",
       "Let's adjust the code to ensure the data is prepared correctly for the model. We'll update the way the dataset is created to explicitly define a structure that separates the features from the labels right before they are batched. This structure will prevent the tuple issue when accessing the data in the `compute_loss` method:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "import tensorflow as tf\n",
       "import tensorflow_recommenders as tfrs\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('final_merged_df.csv')  # Update to your dataset's correct path\n",
       "\n",
       "# Basic preprocessing\n",
       "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
       "\n",
       "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
       "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
       "\n",
       "# Normalize continuous features\n",
       "for feature in ['duration', 'budget', 'revenue']:\n",
       "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
       "\n",
       "# Split the dataset\n",
       "train = df_model.sample(frac=0.8, random_state=42)\n",
       "test = df_model.drop(train.index)\n",
       "\n",
       "# Correctly structure the dataset for TensorFlow\n",
       "def map_func(features, label):\n",
       "    return features, label\n",
       "\n",
       "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
       "train_labels = np.array(train['imdb_score'])\n",
       "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
       "test_labels = np.array(test['imdb_score'])\n",
       "\n",
       "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
       "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
       "\n",
       "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "\n",
       "# Model definition remains the same\n",
       "class MovieRatingModel(tfrs.Model):\n",
       "\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        self.movie_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(32, activation='relu')\n",
       "        ])\n",
       "        self.rating_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(1)\n",
       "        ])\n",
       "        self.task = tfrs.tasks.Ranking(\n",
       "            loss=tf.keras.losses.MeanSquaredError(),\n",
       "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
       "        )\n",
       "\n",
       "    def call(self, features):\n",
       "        movie_embeddings = self.movie_model(features)\n",
       "        return self.rating_model(movie_embeddings)\n",
       "\n",
       "    def compute_loss(self, features, training=False):\n",
       "        # Adjusted to expect a tuple as input\n",
       "        features, labels = features  # Unpack the tuple\n",
       "        rating_predictions = self.call(features)\n",
       "\n",
       "        return self.task(labels=labels, predictions=rating_predictions)\n",
       "\n",
       "# Compile and fit the model\n",
       "model = MovieRatingModel()\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "```\n",
       "\n",
       "This modification ensures the `train_ds` and `test_ds` datasets are structured correctly, addressing the root cause of the AttributeError you encountered. By mapping the dataset into the correct format `(features, labels)` before batching, we ensure that the model receives the input in the expected structure, allowing the `compute_loss` method to work as intended.\n",
       "\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using prompt_error to define a prompt to resolve the error encountered\n",
    "prompt4 = prompt_error(prev_response, err)\n",
    "msg_4 = get_resp_oai(prompt4,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_4, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de0f8cf2-5d5f-4e73-af0c-ec872519bc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"o\">---</span>\n",
       "\n",
       "<span class=\"err\">```</span><span class=\"n\">python</span>\n",
       "<span class=\"c1\"># It seems the issue arises from how the data is passed to the `compute_loss` method. The error message you shared suggests that the `features` variable, expected to be a dictionary or a similar object from which you can `pop` the &#39;imdb_score&#39; key, is actually being received as a tuple. This mismatch typically happens when the dataset provided to the TensorFlow model does not match the expected shape or structure.</span>\n",
       "<span class=\"c1\"># </span>\n",
       "<span class=\"c1\"># Let&#39;s adjust the code to ensure the data is prepared correctly for the model. We&#39;ll update the way the dataset is created to explicitly define a structure that separates the features from the labels right before they are batched. This structure will prevent the tuple issue when accessing the data in the `compute_loss` method:</span>\n",
       "\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow_recommenders</span> <span class=\"k\">as</span> <span class=\"nn\">tfrs</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "\n",
       "<span class=\"c1\"># Load the dataset</span>\n",
       "<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;final_merged_df.csv&#39;</span><span class=\"p\">)</span>  <span class=\"c1\"># Update to your dataset&#39;s correct path</span>\n",
       "\n",
       "<span class=\"c1\"># Basic preprocessing</span>\n",
       "<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(),</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Action&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Adventure&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Animation&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]</span>\n",
       "<span class=\"n\">df_model</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">features</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>  <span class=\"c1\"># This is where the copy is made to avoid SettingWithCopyWarning</span>\n",
       "\n",
       "<span class=\"c1\"># Normalize continuous features</span>\n",
       "<span class=\"k\">for</span> <span class=\"n\">feature</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">]:</span>\n",
       "    <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span> <span class=\"o\">/</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"c1\"># Split the dataset</span>\n",
       "<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">frac</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Correctly structure the dataset for TensorFlow</span>\n",
       "<span class=\"k\">def</span> <span class=\"nf\">map_func</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span>\n",
       "\n",
       "<span class=\"n\">train_features</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"ow\">in</span> <span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<span class=\"n\">train_labels</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">])</span>\n",
       "<span class=\"n\">test_features</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"ow\">in</span> <span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<span class=\"n\">test_labels</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">])</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"n\">train_features</span><span class=\"p\">,</span> <span class=\"n\">train_labels</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">map_func</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"n\">test_features</span><span class=\"p\">,</span> <span class=\"n\">test_labels</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">map_func</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">train_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">test_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Model definition remains the same</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">MovieRatingModel</span><span class=\"p\">(</span><span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">):</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "          <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">tasks</span><span class=\"o\">.</span><span class=\"n\">Ranking</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">MeanSquaredError</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">RootMeanSquaredError</span><span class=\"p\">()]</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">call</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">movie_embeddings</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span><span class=\"p\">(</span><span class=\"n\">movie_embeddings</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">compute_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">training</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
       "        <span class=\"c1\"># Adjusted to expect a tuple as input</span>\n",
       "        <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">features</span>  <span class=\"c1\"># Unpack the tuple</span>\n",
       "        <span class=\"n\">rating_predictions</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">call</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">predictions</span><span class=\"o\">=</span><span class=\"n\">rating_predictions</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Compile and fit the model</span>\n",
       "<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">MovieRatingModel</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">))</span>\n",
       "\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Evaluate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># This modification ensures the `train_ds` and `test_ds` datasets are structured correctly, addressing the root cause of the AttributeError you encountered. By mapping the dataset into the correct format `(features, labels)` before batching, we ensure that the model receives the input in the expected structure, allowing the `compute_loss` method to work as intended.</span>\n",
       "<span class=\"err\">```</span>\n",
       "\n",
       "<span class=\"o\">---</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\\PY{n}{python}\n",
       "\\PY{c+c1}{\\PYZsh{} It seems the issue arises from how the data is passed to the `compute\\PYZus{}loss` method. The error message you shared suggests that the `features` variable, expected to be a dictionary or a similar object from which you can `pop` the \\PYZsq{}imdb\\PYZus{}score\\PYZsq{} key, is actually being received as a tuple. This mismatch typically happens when the dataset provided to the TensorFlow model does not match the expected shape or structure.}\n",
       "\\PY{c+c1}{\\PYZsh{} }\n",
       "\\PY{c+c1}{\\PYZsh{} Let\\PYZsq{}s adjust the code to ensure the data is prepared correctly for the model. We\\PYZsq{}ll update the way the dataset is created to explicitly define a structure that separates the features from the labels right before they are batched. This structure will prevent the tuple issue when accessing the data in the `compute\\PYZus{}loss` method:}\n",
       "\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow} \\PY{k}{as} \\PY{n+nn}{tf}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow\\PYZus{}recommenders} \\PY{k}{as} \\PY{n+nn}{tfrs}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Load the dataset}\n",
       "\\PY{n}{df} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{final\\PYZus{}merged\\PYZus{}df.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} Update to your dataset\\PYZsq{}s correct path}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Basic preprocessing}\n",
       "\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{fillna}\\PY{p}{(}\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Action}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Adventure}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Animation}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n",
       "\\PY{n}{df\\PYZus{}model} \\PY{o}{=} \\PY{n}{df}\\PY{p}{[}\\PY{n}{features}\\PY{p}{]}\\PY{o}{.}\\PY{n}{copy}\\PY{p}{(}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} This is where the copy is made to avoid SettingWithCopyWarning}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Normalize continuous features}\n",
       "\\PY{k}{for} \\PY{n}{feature} \\PY{o+ow}{in} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{:}\n",
       "    \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{=} \\PY{p}{(}\\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{\\PYZhy{}} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)} \\PY{o}{/} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{std}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Split the dataset}\n",
       "\\PY{n}{train} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{sample}\\PY{p}{(}\\PY{n}{frac}\\PY{o}{=}\\PY{l+m+mf}{0.8}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\\PY{n}{test} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{n}{train}\\PY{o}{.}\\PY{n}{index}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Correctly structure the dataset for TensorFlow}\n",
       "\\PY{k}{def} \\PY{n+nf}{map\\PYZus{}func}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{label}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{return} \\PY{n}{features}\\PY{p}{,} \\PY{n}{label}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}features} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{n}{name}\\PY{p}{:} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{value}\\PY{p}{)} \\PY{k}{for} \\PY{n}{name}\\PY{p}{,} \\PY{n}{value} \\PY{o+ow}{in} \\PY{n}{train}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\n",
       "\\PY{n}{train\\PYZus{}labels} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{train}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}features} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{n}{name}\\PY{p}{:} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{value}\\PY{p}{)} \\PY{k}{for} \\PY{n}{name}\\PY{p}{,} \\PY{n}{value} \\PY{o+ow}{in} \\PY{n}{test}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\n",
       "\\PY{n}{test\\PYZus{}labels} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{test}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n}{train\\PYZus{}features}\\PY{p}{,} \\PY{n}{train\\PYZus{}labels}\\PY{p}{)}\\PY{p}{)}\\PY{o}{.}\\PY{n}{map}\\PY{p}{(}\\PY{n}{map\\PYZus{}func}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n}{test\\PYZus{}features}\\PY{p}{,} \\PY{n}{test\\PYZus{}labels}\\PY{p}{)}\\PY{p}{)}\\PY{o}{.}\\PY{n}{map}\\PY{p}{(}\\PY{n}{map\\PYZus{}func}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{train\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{test\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Model definition remains the same}\n",
       "\\PY{k}{class} \\PY{n+nc}{MovieRatingModel}\\PY{p}{(}\\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{Model}\\PY{p}{)}\\PY{p}{:}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "          \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task} \\PY{o}{=} \\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{tasks}\\PY{o}{.}\\PY{n}{Ranking}\\PY{p}{(}\n",
       "            \\PY{n}{loss}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{losses}\\PY{o}{.}\\PY{n}{MeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{metrics}\\PY{o}{=}\\PY{p}{[}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{metrics}\\PY{o}{.}\\PY{n}{RootMeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{]}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{call}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{movie\\PYZus{}embeddings} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model}\\PY{p}{(}\\PY{n}{movie\\PYZus{}embeddings}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{compute\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{,} \\PY{n}{training}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} Adjusted to expect a tuple as input}\n",
       "        \\PY{n}{features}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{features}  \\PY{c+c1}{\\PYZsh{} Unpack the tuple}\n",
       "        \\PY{n}{rating\\PYZus{}predictions} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{call}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task}\\PY{p}{(}\\PY{n}{labels}\\PY{o}{=}\\PY{n}{labels}\\PY{p}{,} \\PY{n}{predictions}\\PY{o}{=}\\PY{n}{rating\\PYZus{}predictions}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Compile and fit the model}\n",
       "\\PY{n}{model} \\PY{o}{=} \\PY{n}{MovieRatingModel}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{compile}\\PY{p}{(}\\PY{n}{optimizer}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{optimizers}\\PY{o}{.}\\PY{n}{Adam}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.001}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{train\\PYZus{}ds}\\PY{p}{,} \\PY{n}{epochs}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{validation\\PYZus{}data}\\PY{o}{=}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Evaluate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{evaluate}\\PY{p}{(}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} This modification ensures the `train\\PYZus{}ds` and `test\\PYZus{}ds` datasets are structured correctly, addressing the root cause of the AttributeError you encountered. By mapping the dataset into the correct format `(features, labels)` before batching, we ensure that the model receives the input in the expected structure, allowing the `compute\\PYZus{}loss` method to work as intended.}\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\n",
       "\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "```python\n",
       "# It seems the issue arises from how the data is passed to the `compute_loss` method. The error message you shared suggests that the `features` variable, expected to be a dictionary or a similar object from which you can `pop` the 'imdb_score' key, is actually being received as a tuple. This mismatch typically happens when the dataset provided to the TensorFlow model does not match the expected shape or structure.\n",
       "# \n",
       "# Let's adjust the code to ensure the data is prepared correctly for the model. We'll update the way the dataset is created to explicitly define a structure that separates the features from the labels right before they are batched. This structure will prevent the tuple issue when accessing the data in the `compute_loss` method:\n",
       "\n",
       "import pandas as pd\n",
       "import tensorflow as tf\n",
       "import tensorflow_recommenders as tfrs\n",
       "import numpy as np\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('final_merged_df.csv')  # Update to your dataset's correct path\n",
       "\n",
       "# Basic preprocessing\n",
       "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
       "\n",
       "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
       "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
       "\n",
       "# Normalize continuous features\n",
       "for feature in ['duration', 'budget', 'revenue']:\n",
       "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
       "\n",
       "# Split the dataset\n",
       "train = df_model.sample(frac=0.8, random_state=42)\n",
       "test = df_model.drop(train.index)\n",
       "\n",
       "# Correctly structure the dataset for TensorFlow\n",
       "def map_func(features, label):\n",
       "    return features, label\n",
       "\n",
       "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
       "train_labels = np.array(train['imdb_score'])\n",
       "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
       "test_labels = np.array(test['imdb_score'])\n",
       "\n",
       "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
       "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
       "\n",
       "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "\n",
       "# Model definition remains the same\n",
       "class MovieRatingModel(tfrs.Model):\n",
       "\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        self.movie_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(32, activation='relu')\n",
       "        ])\n",
       "        self.rating_model = tf.keras.Sequential([\n",
       "          tf.keras.layers.Dense(64, activation='relu'),\n",
       "          tf.keras.layers.Dense(1)\n",
       "        ])\n",
       "        self.task = tfrs.tasks.Ranking(\n",
       "            loss=tf.keras.losses.MeanSquaredError(),\n",
       "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
       "        )\n",
       "\n",
       "    def call(self, features):\n",
       "        movie_embeddings = self.movie_model(features)\n",
       "        return self.rating_model(movie_embeddings)\n",
       "\n",
       "    def compute_loss(self, features, training=False):\n",
       "        # Adjusted to expect a tuple as input\n",
       "        features, labels = features  # Unpack the tuple\n",
       "        rating_predictions = self.call(features)\n",
       "\n",
       "        return self.task(labels=labels, predictions=rating_predictions)\n",
       "\n",
       "# Compile and fit the model\n",
       "model = MovieRatingModel()\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "\n",
       "# This modification ensures the `train_ds` and `test_ds` datasets are structured correctly, addressing the root cause of the AttributeError you encountered. By mapping the dataset into the correct format `(features, labels)` before batching, we ensure that the model receives the input in the expected structure, allowing the `compute_loss` method to work as intended.\n",
       "```\n",
       "\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt5 = helper_extraction_prompt(msg_4)\n",
    "msg_5 = get_resp_oai(prompt5,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_5, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01affe4e-5dd5-4b53-82b2-6d0114a9c188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"<string>\", line 67, in compute_loss\n        \n    File \"<string>\", line 61, in call\n        \n    File \"/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_5' (type Sequential).\n    \n    Layer \"dense_8\" expects 1 input(s), but it received 6 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>]\n    \n    Call arguments received by layer 'sequential_5' (type Sequential):\n      â¢ inputs={'duration': 'tf.Tensor(shape=(None,), dtype=float64)', 'Genre_Action': 'tf.Tensor(shape=(None,), dtype=int64)', 'Genre_Adventure': 'tf.Tensor(shape=(None,), dtype=int64)', 'Genre_Animation': 'tf.Tensor(shape=(None,), dtype=int64)', 'budget': 'tf.Tensor(shape=(None,), dtype=float64)', 'revenue': 'tf.Tensor(shape=(None,), dtype=float64)'}\n      â¢ training=None\n      â¢ mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg_5\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m---\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m```python\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmsg_5\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m```\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m---\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:75\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filejo7rd7xr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 68\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;66;03m# Handle regularization losses as well.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m   regularization_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "File \u001b[0;32m<string>:67\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(self, features, training)\u001b[0m\n",
      "File \u001b[0;32m<string>:61\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(self, features)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.11/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"<string>\", line 67, in compute_loss\n        \n    File \"<string>\", line 61, in call\n        \n    File \"/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_5' (type Sequential).\n    \n    Layer \"dense_8\" expects 1 input(s), but it received 6 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>]\n    \n    Call arguments received by layer 'sequential_5' (type Sequential):\n      â¢ inputs={'duration': 'tf.Tensor(shape=(None,), dtype=float64)', 'Genre_Action': 'tf.Tensor(shape=(None,), dtype=int64)', 'Genre_Adventure': 'tf.Tensor(shape=(None,), dtype=int64)', 'Genre_Animation': 'tf.Tensor(shape=(None,), dtype=int64)', 'budget': 'tf.Tensor(shape=(None,), dtype=float64)', 'revenue': 'tf.Tensor(shape=(None,), dtype=float64)'}\n      â¢ training=None\n      â¢ mask=None\n"
     ]
    }
   ],
   "source": [
    "exec(msg_5[len(\"---\\n\\n```python\\n\"):len(msg_5)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4152d-a771-4b9f-a11f-6237a5fbb826",
   "metadata": {},
   "source": [
    "#### Human intervention required to resolve all errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e282da8d-dc42-405c-bde2-0082530fd52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 2s 6ms/step - root_mean_squared_error: 3.9364 - loss: 15.3092 - regularization_loss: 0.0000e+00 - total_loss: 15.3092 - val_root_mean_squared_error: 1.7594 - val_loss: 2.5595 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.5595\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 1.4347 - loss: 2.0362 - regularization_loss: 0.0000e+00 - total_loss: 2.0362 - val_root_mean_squared_error: 1.0751 - val_loss: 1.0504 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0504\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 1.0130 - loss: 1.0184 - regularization_loss: 0.0000e+00 - total_loss: 1.0184 - val_root_mean_squared_error: 0.9839 - val_loss: 1.1619 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.1619\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9528 - loss: 0.9020 - regularization_loss: 0.0000e+00 - total_loss: 0.9020 - val_root_mean_squared_error: 0.9694 - val_loss: 1.1879 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.1879\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 4ms/step - root_mean_squared_error: 0.9369 - loss: 0.8725 - regularization_loss: 0.0000e+00 - total_loss: 0.8725 - val_root_mean_squared_error: 0.9662 - val_loss: 1.2001 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2001\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 4ms/step - root_mean_squared_error: 0.9306 - loss: 0.8610 - regularization_loss: 0.0000e+00 - total_loss: 0.8610 - val_root_mean_squared_error: 0.9654 - val_loss: 1.2133 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2133\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 4ms/step - root_mean_squared_error: 0.9277 - loss: 0.8558 - regularization_loss: 0.0000e+00 - total_loss: 0.8558 - val_root_mean_squared_error: 0.9656 - val_loss: 1.2166 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2166\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9261 - loss: 0.8530 - regularization_loss: 0.0000e+00 - total_loss: 0.8530 - val_root_mean_squared_error: 0.9658 - val_loss: 1.2177 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2177\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9247 - loss: 0.8504 - regularization_loss: 0.0000e+00 - total_loss: 0.8504 - val_root_mean_squared_error: 0.9662 - val_loss: 1.2173 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2173\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 4ms/step - root_mean_squared_error: 0.9235 - loss: 0.8484 - regularization_loss: 0.0000e+00 - total_loss: 0.8484 - val_root_mean_squared_error: 0.9660 - val_loss: 1.2177 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2177\n",
      "26/26 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9660 - loss: 0.9447 - regularization_loss: 0.0000e+00 - total_loss: 0.9447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9660033583641052, 1.2177084684371948, 0, 1.2177084684371948]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('final_merged_df.csv')  \n",
    "\n",
    "# Basic preprocessing\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "\n",
    "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "# Correctly structure the dataset for TensorFlow\n",
    "def map_func(features, label):\n",
    "    return features, label\n",
    "\n",
    "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
    "train_labels = np.array(train['imdb_score'])\n",
    "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
    "test_labels = np.array(test['imdb_score'])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "class MovieRatingModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),  # Adjusted input shape\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        \n",
    "        # [ modified bit of code ] #\n",
    "        duration = tf.expand_dims(features['duration'], axis=-1)\n",
    "        genre_action = tf.expand_dims(tf.cast(features['Genre_Action'], tf.float32), axis=-1)\n",
    "        genre_adventure = tf.expand_dims(tf.cast(features['Genre_Adventure'], tf.float32), axis=-1)\n",
    "        genre_animation = tf.expand_dims(tf.cast(features['Genre_Animation'], tf.float32), axis=-1)\n",
    "        budget = tf.expand_dims(features['budget'], axis=-1)\n",
    "        revenue = tf.expand_dims(features['revenue'], axis=-1)\n",
    "        \n",
    "        concatenated_features = tf.concat([duration, genre_action, genre_adventure, genre_animation, budget, revenue], axis=1)\n",
    "        # [ modified bit of code ] #\n",
    "        \n",
    "        movie_embeddings = self.movie_model(concatenated_features)\n",
    "        \n",
    "        return self.rating_model(movie_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        features, labels = features\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "# Compile and fit the model\n",
    "model = MovieRatingModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
    "\n",
    "# Evaluate\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "342e3d20-b403-4c6a-bab7-b5fa5efc3462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.9, 7.1, 6.8, 8.5, 6.6, 6.2, 7.8, 7.5, 6.9, 6.1, 6.7, 7.3, 6.5,\n",
       "       7.2, 8.1, 7. , 7.7, 8.2, 5.9, 6. , 5.7, 6.3, 5.6, 8.3, 8. , 8.4,\n",
       "       5.8, 5.4, 9. , 4.8, 5.2, 7.6, 4.5, 6.4, 5.5, 8.6, 8.8, 5.1, 7.4,\n",
       "       4.2, 5. , 4.9, 3.7, 5.3, 4.3, 3.8, 4.4, 3.3, 2.2, 8.9, 8.7, 4.6,\n",
       "       2.4, 3.4, 4.1, 4.7, 3. , 3.6, 1.7, 4. , 2.7, 2. , 3.5, 9.3, 2.9,\n",
       "       3.9, 2.8, 2.3, 1.9, 3.1, 1.6, 2.5, 2.1, 9.2, 3.2, 9.1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['imdb_score'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f5322-ebb2-456b-b125-f245bb81df4b",
   "metadata": {},
   "source": [
    "- In this case, the RMSE value of approximately 0.966 on the test dataset signifies that, on average, the model's predictions deviate from the actual IMDb scores by around 0.966 points.\n",
    "- Interpreting this value in the context of IMDb scores, where ratings typically range from 1 to 10, a RMSE of 0.966 indicates that the model's predictions are reasonably accurate. It implies that the majority of the model's predictions are within approximately 1 point of the actual IMDb scores. Therefore, the lower the RMSE, the higher the accuracy of the model's predictions. In summary, a RMSE of 0.966 suggests that the model is performing well in predicting IMDb scores based on the given features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca71c5a-b832-4186-95bd-b0a7073e19fe",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "The model shows promising performance with decreasing training and validation RMSE, indicating effective learning and generalisation. Consistent reduction in loss during training suggests minimized prediction errors. Lack of regularisation loss suggests the model avoids overfitting. The test dataset's RMSE of approximately 0.966 signifies accurate predictions with a reasonable margin of error. Overall, the model demonstrates robust performance in predicting IMDb scores based on the provided features, with most predictions within 1 point of actual scores. This implies that the choosen LLM illustrates a promising potential to design effective NN arhitectures for specified tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a95c07-ed7a-4471-8fbe-a60ef7fe9e98",
   "metadata": {},
   "source": [
    "# Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6eaabaff-a637-47c9-82ee-506eba8ca02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key= 'wx2BQHdz8yBJw318NlkHGG3PfvlFM0l0d315rmH2lv8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb5d88ed-3989-4fe2-8a2d-c86544789790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resp_oai(input_text, model):\n",
    "    url = \"https://llm.api.ai8.io/query_llm\"\n",
    "    data = {\n",
    "        # Specify the model that you want to use\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You act as a highly intelligent system. Your job is to analyse the movie data and predict the rating scores of movies considering various movie features\"},\n",
    "                    {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    }\n",
    "    headers = {'Authorization': api_key}\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        response_data = json.loads(response.content)\n",
    "        model_response = extract_message_oai(response_data)\n",
    "        return model_response\n",
    "    else:\n",
    "        return {\"statusCode\": response.status_code, \"body\": response.content}\n",
    "\n",
    "def extract_message_oai(response_data):\n",
    "    message_content = response_data.get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    # format the extracted message as markdown\n",
    "    markdown_content = \"---\\n\\n\" + message_content + \"\\n\\n---\"\n",
    "    return markdown_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c44c8f02-3c2a-4744-b219-d7d8f10a48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('final_merged_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf8d3c-a036-4f91-939c-5d2857efd2df",
   "metadata": {},
   "source": [
    "Running the model with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dafe14a3-d712-4067-9325-c000fe425b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'movie_rating_model_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 13.9802 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 4.9454 - total_loss: 13.9802 - val_loss: 3.0186 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.8108 - val_total_loss: 3.0186\n",
      "Epoch 2/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.5001 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 1.7607 - total_loss: 2.5001 - val_loss: 1.1705 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.2201 - val_total_loss: 1.1705\n",
      "Epoch 3/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1821 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 1.1679 - total_loss: 1.1821 - val_loss: 1.1696 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9974 - val_total_loss: 1.1696\n",
      "Epoch 4/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9278 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9794 - total_loss: 0.9278 - val_loss: 1.2281 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9716 - val_total_loss: 1.2281\n",
      "Epoch 5/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8828 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9459 - total_loss: 0.8828 - val_loss: 1.2264 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9656 - val_total_loss: 1.2264\n",
      "Epoch 6/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8692 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9365 - total_loss: 0.8692 - val_loss: 1.2285 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9631 - val_total_loss: 1.2285\n",
      "Epoch 7/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8634 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9326 - total_loss: 0.8634 - val_loss: 1.2229 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9617 - val_total_loss: 1.2229\n",
      "Epoch 8/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8592 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9304 - total_loss: 0.8592 - val_loss: 1.2230 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9614 - val_total_loss: 1.2230\n",
      "Epoch 9/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8569 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9289 - total_loss: 0.8569 - val_loss: 1.2318 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9619 - val_total_loss: 1.2318\n",
      "Epoch 10/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8543 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9275 - total_loss: 0.8543 - val_loss: 1.2335 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9621 - val_total_loss: 1.2335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc4f82f49d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Basic preprocessing\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "\n",
    "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "# Correctly structure the dataset for TensorFlow\n",
    "def map_func(features, label):\n",
    "    return features, label\n",
    "\n",
    "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
    "train_labels = np.array(train['imdb_score'])\n",
    "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
    "test_labels = np.array(test['imdb_score'])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "class MovieRatingModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),  # Adjusted input shape\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        \n",
    "        # [ modified bit of code ] #\n",
    "        duration = tf.expand_dims(features['duration'], axis=-1)\n",
    "        genre_action = tf.expand_dims(tf.cast(features['Genre_Action'], tf.float32), axis=-1)\n",
    "        genre_adventure = tf.expand_dims(tf.cast(features['Genre_Adventure'], tf.float32), axis=-1)\n",
    "        genre_animation = tf.expand_dims(tf.cast(features['Genre_Animation'], tf.float32), axis=-1)\n",
    "        budget = tf.expand_dims(features['budget'], axis=-1)\n",
    "        revenue = tf.expand_dims(features['revenue'], axis=-1)\n",
    "        \n",
    "        concatenated_features = tf.concat([duration, genre_action, genre_adventure, genre_animation, budget, revenue], axis=1)\n",
    "        # [ modified bit of code ] #\n",
    "        \n",
    "        movie_embeddings = self.movie_model(concatenated_features)\n",
    "        \n",
    "        return self.rating_model(movie_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        features, labels = features\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "# Compile and fit the model\n",
    "model = MovieRatingModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "297e1db1-4492-4061-97ea-4111cc0a767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  Genre_Action  Genre_Adventure  Genre_Animation    budget  \\\n",
      "0  3.133589             1                1                0  4.851404   \n",
      "1  2.725783             1                1                0  6.343649   \n",
      "2  1.774236             1                1                0  5.040895   \n",
      "3  2.499224             1                0                0  5.159328   \n",
      "4  1.049248             1                1                0  5.396192   \n",
      "\n",
      "     revenue  imdb_score  \n",
      "0  15.796650         7.9  \n",
      "1   5.092535         7.1  \n",
      "2   4.621912         6.8  \n",
      "3   5.818689         8.5  \n",
      "4   1.126834         6.6  \n"
     ]
    }
   ],
   "source": [
    "print(df_model.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06bbf205-669c-4159-9948-742a5497a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_prompt_learning_rate():\n",
    "    prompt = \"\"\"\n",
    "Task Description:\n",
    "Provide me with the full code that modifies the existing model to adjust the learning rate in the optimizer to 0.05. This change aims to observe the impact of a higher learning rate on the model's training performance and prediction accuracy for movie ratings.\n",
    "\n",
    "Current Setup:\n",
    "- The model uses TensorFlow and TensorFlow Recommenders libraries.\n",
    "- The current learning rate in the Adam optimizer is set at 0.001.\n",
    "\n",
    "Required Modification:\n",
    "- Provide the full code that increases the learning rate in the Adam optimizer from 0.001 to 0.05. Ensure that your response separates code from explanatory text.\n",
    "\n",
    "Objectives:\n",
    "- Implement the learning rate change with the rest of the code.\n",
    "- Observe and document the effects on model training and accuracy.\n",
    "- Keep the model architecture unchanged.\n",
    "- Ensure that code is separated from text.\n",
    "\n",
    "Expected Deliverables:\n",
    "1. Adjust the following Python code to apply the new learning rate and document the changes inline. Provide the python code seperately from the explanations. Make sure that the code combines the full model.\n",
    "2. Consider that the df is already loaded in the environment.\n",
    "\n",
    "\n",
    "This is the already established model:\n",
    "```python\n",
    "# Basic preprocessing\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "\n",
    "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "# Correctly structure the dataset for TensorFlow\n",
    "def map_func(features, label):\n",
    "    return features, label\n",
    "\n",
    "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
    "train_labels = np.array(train['imdb_score'])\n",
    "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
    "test_labels = np.array(test['imdb_score'])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "class MovieRatingModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),  # Adjusted input shape\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        \n",
    "        # [ modified bit of code ] #\n",
    "        duration = tf.expand_dims(features['duration'], axis=-1)\n",
    "        genre_action = tf.expand_dims(tf.cast(features['Genre_Action'], tf.float32), axis=-1)\n",
    "        genre_adventure = tf.expand_dims(tf.cast(features['Genre_Adventure'], tf.float32), axis=-1)\n",
    "        genre_animation = tf.expand_dims(tf.cast(features['Genre_Animation'], tf.float32), axis=-1)\n",
    "        budget = tf.expand_dims(features['budget'], axis=-1)\n",
    "        revenue = tf.expand_dims(features['revenue'], axis=-1)\n",
    "        \n",
    "        concatenated_features = tf.concat([duration, genre_action, genre_adventure, genre_animation, budget, revenue], axis=1)\n",
    "        # [ modified bit of code ] #\n",
    "        \n",
    "        movie_embeddings = self.movie_model(concatenated_features)\n",
    "        \n",
    "        return self.rating_model(movie_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        features, labels = features\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "# Compile and fit the model\n",
    "model = MovieRatingModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
    "\n",
    "# Evaluate\n",
    "model.evaluate(test_ds)\n",
    "\n",
    "- Documenting observations:\n",
    " The increased learning rate is intended to test faster convergence capabilities\n",
    " Careful monitoring of model performance metrics is crucial to assess the benefits or drawbacks of this adjustment.\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f4784a4-1925-4e75-9f84-b4a270657891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert response string into an executable format: prompt 3, 5\n",
    "def helper_extraction_prompt(resp_str):\n",
    "    return f\"Can you transform this string: {resp_str} into an executable string by extracting the python code and keeping the rest of the information as comments?Skip introductory text. Please place comment symbols where nessesary.Keep in mind that the given response string will be executed in a python code chunk using the function :'exec(given_response_string).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74cf2ecb-10f6-4e99-85e8-9686e6314faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style='color: #34568B;'>\n",
       "\n",
       "---\n",
       "\n",
       "To modify the given model to use a higher learning rate of 0.05, you need to adjust the `optimizer` parameter in the `model.compile()` step. Here's how the updated section of the code looks:\n",
       "\n",
       "```python\n",
       "# Compile and fit the model with an adjusted learning rate\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "```\n",
       "\n",
       "### Full Modified Code:\n",
       "\n",
       "```python\n",
       "import tensorflow as tf\n",
       "import tensorflow_recommenders as tfrs\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "\n",
       "# Assume df is already loaded in your environment\n",
       "# Basic preprocessing\n",
       "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
       "\n",
       "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
       "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
       "\n",
       "# Normalize continuous features\n",
       "for feature in ['duration', 'budget', 'revenue']:\n",
       "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
       "\n",
       "# Split the dataset\n",
       "train = df_model.sample(frac=0.8, random_state=42)\n",
       "test = df_model.drop(train.index)\n",
       "\n",
       "def map_func(features, label):\n",
       "    return features, label\n",
       "\n",
       "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
       "train_labels = np.array(train['imdb_score'])\n",
       "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
       "test_labels = np.array(test['imdb_score'])\n",
       "\n",
       "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
       "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
       "\n",
       "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "\n",
       "class MovieRatingModel(tfrs.Model):\n",
       "\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        self.movie_model = tf.keras.Sequential([\n",
       "            tf.keras.layers.Dense(64, activation='relu'),\n",
       "            tf.keras.layers.Dense(32, activation='relu')\n",
       "        ])\n",
       "        self.rating_model = tf.keras.Sequential([\n",
       "            tf.keras.layers.Dense(64, activation='relu'),\n",
       "            tf.keras.layers.Dense(1)\n",
       "        ])\n",
       "        self.task = tfrs.tasks.Ranking(\n",
       "            loss=tf.keras.losses.MeanSquaredError(),\n",
       "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
       "        )\n",
       "\n",
       "    def call(self, features):\n",
       "        duration = tf.expand_dims(features['duration'], axis=-1)\n",
       "        genre_action = tf.expand_dims(tf.cast(features['Genre_Action'], tf.float32), axis=-1)\n",
       "        genre_adventure = tf.expand_dims(tf.cast(features['Genre_Adventure'], tf.float32), axis=-1)\n",
       "        genre_animation = tf.expand_dims(tf.cast(features['Genre_Animation'], tf.float32), axis=-1)\n",
       "        budget = tf.expand_dims(features['budget'], axis=-1)\n",
       "        revenue = tf.expand_dims(features['revenue'], axis=-1)\n",
       "        \n",
       "        concatenated_features = tf.concat([duration, genre_action, genre_adventure, genre_animation, budget, revenue], axis=1)\n",
       "        \n",
       "        movie_embeddings = self.movie_model(concatenated_features)\n",
       "        \n",
       "        return self.rating_model(movie_embeddings)\n",
       "\n",
       "    def compute_loss(self, features, training=False):\n",
       "        features, labels = features\n",
       "        rating_predictions = self(features)\n",
       "\n",
       "        return self.task(labels=labels, predictions=rating_predictions)\n",
       "\n",
       "# Compile and fit the model with an adjusted learning rate\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "```\n",
       "\n",
       "### Observing Changes:\n",
       "\n",
       "When you modify the learning rate to 0.05, it's essential to monitor:\n",
       "\n",
       "- **Training Loss and Validation Loss**: A higher learning rate can lead to faster convergence, but it might also overshoot the minimum, leading to potentially higher loss after initial improvement.\n",
       "- **Accuracy Metrics**: In this case, RMSE (root mean squared error) would be a critical metric. Observe whether it decreases more quickly, stagnates, or even increases due to the higher learning rate.\n",
       "- **Overfitting**: Ensure that the model isn't just memorizing the training data. A significant gap between training and validation metrics might indicate overfitting.\n",
       "\n",
       "If you encounter negative impacts, consider using techniques such as learning rate schedules or decay to adjust the learning rate dynamically during training.\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_lr_1 = define_prompt_learning_rate()\n",
    "msg_lr_1 = get_resp_oai(prompt_lr_1,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_lr_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f52bfc00-b272-48aa-8813-22f22dbea319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"o\">---</span>\n",
       "\n",
       "<span class=\"err\">```</span><span class=\"n\">python</span>\n",
       "<span class=\"c1\"># Compile and fit the model with an adjusted learning rate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.05</span><span class=\"p\">))</span>\n",
       "\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Evaluate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">### Full Modified Code:</span>\n",
       "<span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow_recommenders</span> <span class=\"k\">as</span> <span class=\"nn\">tfrs</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "\n",
       "<span class=\"c1\"># Assume df is already loaded in your environment</span>\n",
       "<span class=\"c1\"># Basic preprocessing</span>\n",
       "<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(),</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Action&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Adventure&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Genre_Animation&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">]</span>\n",
       "<span class=\"n\">df_model</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">features</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>  <span class=\"c1\"># This is where the copy is made to avoid SettingWithCopyWarning</span>\n",
       "\n",
       "<span class=\"c1\"># Normalize continuous features</span>\n",
       "<span class=\"k\">for</span> <span class=\"n\">feature</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">]:</span>\n",
       "    <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">())</span> <span class=\"o\">/</span> <span class=\"n\">df_model</span><span class=\"p\">[</span><span class=\"n\">feature</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"c1\"># Split the dataset</span>\n",
       "<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">frac</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">df_model</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">map_func</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span>\n",
       "\n",
       "<span class=\"n\">train_features</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"ow\">in</span> <span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<span class=\"n\">train_labels</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">])</span>\n",
       "<span class=\"n\">test_features</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"ow\">in</span> <span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<span class=\"n\">test_labels</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"p\">[</span><span class=\"s1\">&#39;imdb_score&#39;</span><span class=\"p\">])</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"n\">train_features</span><span class=\"p\">,</span> <span class=\"n\">train_labels</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">map_func</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"n\">test_features</span><span class=\"p\">,</span> <span class=\"n\">test_labels</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">map_func</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">train_ds</span> <span class=\"o\">=</span> <span class=\"n\">train_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">test_ds</span> <span class=\"o\">=</span> <span class=\"n\">test_ds</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">prefetch</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">AUTOTUNE</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">MovieRatingModel</span><span class=\"p\">(</span><span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">):</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">([</span>\n",
       "            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">),</span>\n",
       "            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"p\">])</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">tfrs</span><span class=\"o\">.</span><span class=\"n\">tasks</span><span class=\"o\">.</span><span class=\"n\">Ranking</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">MeanSquaredError</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">RootMeanSquaredError</span><span class=\"p\">()]</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">call</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">duration</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[</span><span class=\"s1\">&#39;duration&#39;</span><span class=\"p\">],</span> <span class=\"n\">axis</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">genre_action</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[</span><span class=\"s1\">&#39;Genre_Action&#39;</span><span class=\"p\">],</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span> <span class=\"n\">axis</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">genre_adventure</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[</span><span class=\"s1\">&#39;Genre_Adventure&#39;</span><span class=\"p\">],</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span> <span class=\"n\">axis</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">genre_animation</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[</span><span class=\"s1\">&#39;Genre_Animation&#39;</span><span class=\"p\">],</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span> <span class=\"n\">axis</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">budget</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[</span><span class=\"s1\">&#39;budget&#39;</span><span class=\"p\">],</span> <span class=\"n\">axis</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">revenue</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[</span><span class=\"s1\">&#39;revenue&#39;</span><span class=\"p\">],</span> <span class=\"n\">axis</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        \n",
       "        <span class=\"n\">concatenated_features</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">concat</span><span class=\"p\">([</span><span class=\"n\">duration</span><span class=\"p\">,</span> <span class=\"n\">genre_action</span><span class=\"p\">,</span> <span class=\"n\">genre_adventure</span><span class=\"p\">,</span> <span class=\"n\">genre_animation</span><span class=\"p\">,</span> <span class=\"n\">budget</span><span class=\"p\">,</span> <span class=\"n\">revenue</span><span class=\"p\">],</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "        \n",
       "        <span class=\"n\">movie_embeddings</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">movie_model</span><span class=\"p\">(</span><span class=\"n\">concatenated_features</span><span class=\"p\">)</span>\n",
       "        \n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">rating_model</span><span class=\"p\">(</span><span class=\"n\">movie_embeddings</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">compute_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">training</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">features</span>\n",
       "        <span class=\"n\">rating_predictions</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">predictions</span><span class=\"o\">=</span><span class=\"n\">rating_predictions</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">MovieRatingModel</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"c1\"># Compile and fit the model with an adjusted learning rate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.05</span><span class=\"p\">))</span>\n",
       "\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">validation_data</span><span class=\"o\">=</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Evaluate</span>\n",
       "<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">test_ds</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">### Observing Changes:</span>\n",
       "\n",
       "<span class=\"sd\">When you modify the learning rate to 0.05, it&#39;s essential to monitor:</span>\n",
       "\n",
       "<span class=\"sd\">- **Training Loss and Validation Loss**: A higher learning rate can lead to faster convergence, but it might also overshoot the minimum, leading to potentially higher loss after initial improvement.</span>\n",
       "<span class=\"sd\">- **Accuracy Metrics**: In this case, RMSE (root mean squared error) would be a critical metric. Observe whether it decreases more quickly, stagnates, or even increases due to the higher learning rate.</span>\n",
       "<span class=\"sd\">- **Overfitting**: Ensure that the model isn&#39;t just memorizing the training data. A significant gap between training and validation metrics might indicate overfitting.</span>\n",
       "\n",
       "<span class=\"sd\">If you encounter negative impacts, consider using techniques such as learning rate schedules or decay to adjust the learning rate dynamically during training.</span>\n",
       "<span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"err\">```</span>\n",
       "\n",
       "<span class=\"o\">---</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\\PY{n}{python}\n",
       "\\PY{c+c1}{\\PYZsh{} Compile and fit the model with an adjusted learning rate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{compile}\\PY{p}{(}\\PY{n}{optimizer}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{optimizers}\\PY{o}{.}\\PY{n}{Adam}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.05}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{train\\PYZus{}ds}\\PY{p}{,} \\PY{n}{epochs}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{validation\\PYZus{}data}\\PY{o}{=}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Evaluate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{evaluate}\\PY{p}{(}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{\\PYZsh{}\\PYZsh{}\\PYZsh{} Full Modified Code:}\n",
       "\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow} \\PY{k}{as} \\PY{n+nn}{tf}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{tensorflow\\PYZus{}recommenders} \\PY{k}{as} \\PY{n+nn}{tfrs}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Assume df is already loaded in your environment}\n",
       "\\PY{c+c1}{\\PYZsh{} Basic preprocessing}\n",
       "\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{fillna}\\PY{p}{(}\\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Action}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Adventure}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Animation}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n",
       "\\PY{n}{df\\PYZus{}model} \\PY{o}{=} \\PY{n}{df}\\PY{p}{[}\\PY{n}{features}\\PY{p}{]}\\PY{o}{.}\\PY{n}{copy}\\PY{p}{(}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} This is where the copy is made to avoid SettingWithCopyWarning}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Normalize continuous features}\n",
       "\\PY{k}{for} \\PY{n}{feature} \\PY{o+ow}{in} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{:}\n",
       "    \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{=} \\PY{p}{(}\\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]} \\PY{o}{\\PYZhy{}} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)} \\PY{o}{/} \\PY{n}{df\\PYZus{}model}\\PY{p}{[}\\PY{n}{feature}\\PY{p}{]}\\PY{o}{.}\\PY{n}{std}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Split the dataset}\n",
       "\\PY{n}{train} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{sample}\\PY{p}{(}\\PY{n}{frac}\\PY{o}{=}\\PY{l+m+mf}{0.8}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\\PY{n}{test} \\PY{o}{=} \\PY{n}{df\\PYZus{}model}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{n}{train}\\PY{o}{.}\\PY{n}{index}\\PY{p}{)}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{map\\PYZus{}func}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{label}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{return} \\PY{n}{features}\\PY{p}{,} \\PY{n}{label}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}features} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{n}{name}\\PY{p}{:} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{value}\\PY{p}{)} \\PY{k}{for} \\PY{n}{name}\\PY{p}{,} \\PY{n}{value} \\PY{o+ow}{in} \\PY{n}{train}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\n",
       "\\PY{n}{train\\PYZus{}labels} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{train}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}features} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{n}{name}\\PY{p}{:} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{value}\\PY{p}{)} \\PY{k}{for} \\PY{n}{name}\\PY{p}{,} \\PY{n}{value} \\PY{o+ow}{in} \\PY{n}{test}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\n",
       "\\PY{n}{test\\PYZus{}labels} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{array}\\PY{p}{(}\\PY{n}{test}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{imdb\\PYZus{}score}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n}{train\\PYZus{}features}\\PY{p}{,} \\PY{n}{train\\PYZus{}labels}\\PY{p}{)}\\PY{p}{)}\\PY{o}{.}\\PY{n}{map}\\PY{p}{(}\\PY{n}{map\\PYZus{}func}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{Dataset}\\PY{o}{.}\\PY{n}{from\\PYZus{}tensor\\PYZus{}slices}\\PY{p}{(}\\PY{p}{(}\\PY{n}{test\\PYZus{}features}\\PY{p}{,} \\PY{n}{test\\PYZus{}labels}\\PY{p}{)}\\PY{p}{)}\\PY{o}{.}\\PY{n}{map}\\PY{p}{(}\\PY{n}{map\\PYZus{}func}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{train\\PYZus{}ds} \\PY{o}{=} \\PY{n}{train\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\\PY{n}{test\\PYZus{}ds} \\PY{o}{=} \\PY{n}{test\\PYZus{}ds}\\PY{o}{.}\\PY{n}{batch}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{o}{.}\\PY{n}{prefetch}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{data}\\PY{o}{.}\\PY{n}{AUTOTUNE}\\PY{p}{)}\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{MovieRatingModel}\\PY{p}{(}\\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{Model}\\PY{p}{)}\\PY{p}{:}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "            \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\\PY{p}{[}\n",
       "            \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{64}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{layers}\\PY{o}{.}\\PY{n}{Dense}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task} \\PY{o}{=} \\PY{n}{tfrs}\\PY{o}{.}\\PY{n}{tasks}\\PY{o}{.}\\PY{n}{Ranking}\\PY{p}{(}\n",
       "            \\PY{n}{loss}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{losses}\\PY{o}{.}\\PY{n}{MeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{metrics}\\PY{o}{=}\\PY{p}{[}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{metrics}\\PY{o}{.}\\PY{n}{RootMeanSquaredError}\\PY{p}{(}\\PY{p}{)}\\PY{p}{]}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{call}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{duration} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{expand\\PYZus{}dims}\\PY{p}{(}\\PY{n}{features}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{duration}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{n}{genre\\PYZus{}action} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{expand\\PYZus{}dims}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{cast}\\PY{p}{(}\\PY{n}{features}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Action}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{)}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{n}{genre\\PYZus{}adventure} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{expand\\PYZus{}dims}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{cast}\\PY{p}{(}\\PY{n}{features}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Adventure}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{)}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{n}{genre\\PYZus{}animation} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{expand\\PYZus{}dims}\\PY{p}{(}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{cast}\\PY{p}{(}\\PY{n}{features}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Genre\\PYZus{}Animation}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{)}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{n}{budget} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{expand\\PYZus{}dims}\\PY{p}{(}\\PY{n}{features}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{budget}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \\PY{n}{revenue} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{expand\\PYZus{}dims}\\PY{p}{(}\\PY{n}{features}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{revenue}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \n",
       "        \\PY{n}{concatenated\\PYZus{}features} \\PY{o}{=} \\PY{n}{tf}\\PY{o}{.}\\PY{n}{concat}\\PY{p}{(}\\PY{p}{[}\\PY{n}{duration}\\PY{p}{,} \\PY{n}{genre\\PYZus{}action}\\PY{p}{,} \\PY{n}{genre\\PYZus{}adventure}\\PY{p}{,} \\PY{n}{genre\\PYZus{}animation}\\PY{p}{,} \\PY{n}{budget}\\PY{p}{,} \\PY{n}{revenue}\\PY{p}{]}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "        \n",
       "        \\PY{n}{movie\\PYZus{}embeddings} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{movie\\PYZus{}model}\\PY{p}{(}\\PY{n}{concatenated\\PYZus{}features}\\PY{p}{)}\n",
       "        \n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{rating\\PYZus{}model}\\PY{p}{(}\\PY{n}{movie\\PYZus{}embeddings}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{compute\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{features}\\PY{p}{,} \\PY{n}{training}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{features}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{features}\n",
       "        \\PY{n}{rating\\PYZus{}predictions} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{p}{(}\\PY{n}{features}\\PY{p}{)}\n",
       "\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task}\\PY{p}{(}\\PY{n}{labels}\\PY{o}{=}\\PY{n}{labels}\\PY{p}{,} \\PY{n}{predictions}\\PY{o}{=}\\PY{n}{rating\\PYZus{}predictions}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{model} \\PY{o}{=} \\PY{n}{MovieRatingModel}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Compile and fit the model with an adjusted learning rate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{compile}\\PY{p}{(}\\PY{n}{optimizer}\\PY{o}{=}\\PY{n}{tf}\\PY{o}{.}\\PY{n}{keras}\\PY{o}{.}\\PY{n}{optimizers}\\PY{o}{.}\\PY{n}{Adam}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.05}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{train\\PYZus{}ds}\\PY{p}{,} \\PY{n}{epochs}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{validation\\PYZus{}data}\\PY{o}{=}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Evaluate}\n",
       "\\PY{n}{model}\\PY{o}{.}\\PY{n}{evaluate}\\PY{p}{(}\\PY{n}{test\\PYZus{}ds}\\PY{p}{)}\n",
       "\n",
       "\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{\\PYZsh{}\\PYZsh{}\\PYZsh{} Observing Changes:}\n",
       "\n",
       "\\PY{l+s+sd}{When you modify the learning rate to 0.05, it\\PYZsq{}s essential to monitor:}\n",
       "\n",
       "\\PY{l+s+sd}{\\PYZhy{} **Training Loss and Validation Loss**: A higher learning rate can lead to faster convergence, but it might also overshoot the minimum, leading to potentially higher loss after initial improvement.}\n",
       "\\PY{l+s+sd}{\\PYZhy{} **Accuracy Metrics**: In this case, RMSE (root mean squared error) would be a critical metric. Observe whether it decreases more quickly, stagnates, or even increases due to the higher learning rate.}\n",
       "\\PY{l+s+sd}{\\PYZhy{} **Overfitting**: Ensure that the model isn\\PYZsq{}t just memorizing the training data. A significant gap between training and validation metrics might indicate overfitting.}\n",
       "\n",
       "\\PY{l+s+sd}{If you encounter negative impacts, consider using techniques such as learning rate schedules or decay to adjust the learning rate dynamically during training.}\n",
       "\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{err}{`}\\PY{err}{`}\\PY{err}{`}\n",
       "\n",
       "\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZhy{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "```python\n",
       "# Compile and fit the model with an adjusted learning rate\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "\n",
       "\"\"\"\n",
       "### Full Modified Code:\n",
       "\"\"\"\n",
       "import tensorflow as tf\n",
       "import tensorflow_recommenders as tfrs\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "\n",
       "# Assume df is already loaded in your environment\n",
       "# Basic preprocessing\n",
       "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
       "\n",
       "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
       "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
       "\n",
       "# Normalize continuous features\n",
       "for feature in ['duration', 'budget', 'revenue']:\n",
       "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
       "\n",
       "# Split the dataset\n",
       "train = df_model.sample(frac=0.8, random_state=42)\n",
       "test = df_model.drop(train.index)\n",
       "\n",
       "def map_func(features, label):\n",
       "    return features, label\n",
       "\n",
       "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
       "train_labels = np.array(train['imdb_score'])\n",
       "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
       "test_labels = np.array(test['imdb_score'])\n",
       "\n",
       "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
       "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
       "\n",
       "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
       "\n",
       "class MovieRatingModel(tfrs.Model):\n",
       "\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        self.movie_model = tf.keras.Sequential([\n",
       "            tf.keras.layers.Dense(64, activation='relu'),\n",
       "            tf.keras.layers.Dense(32, activation='relu')\n",
       "        ])\n",
       "        self.rating_model = tf.keras.Sequential([\n",
       "            tf.keras.layers.Dense(64, activation='relu'),\n",
       "            tf.keras.layers.Dense(1)\n",
       "        ])\n",
       "        self.task = tfrs.tasks.Ranking(\n",
       "            loss=tf.keras.losses.MeanSquaredError(),\n",
       "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
       "        )\n",
       "\n",
       "    def call(self, features):\n",
       "        duration = tf.expand_dims(features['duration'], axis=-1)\n",
       "        genre_action = tf.expand_dims(tf.cast(features['Genre_Action'], tf.float32), axis=-1)\n",
       "        genre_adventure = tf.expand_dims(tf.cast(features['Genre_Adventure'], tf.float32), axis=-1)\n",
       "        genre_animation = tf.expand_dims(tf.cast(features['Genre_Animation'], tf.float32), axis=-1)\n",
       "        budget = tf.expand_dims(features['budget'], axis=-1)\n",
       "        revenue = tf.expand_dims(features['revenue'], axis=-1)\n",
       "        \n",
       "        concatenated_features = tf.concat([duration, genre_action, genre_adventure, genre_animation, budget, revenue], axis=1)\n",
       "        \n",
       "        movie_embeddings = self.movie_model(concatenated_features)\n",
       "        \n",
       "        return self.rating_model(movie_embeddings)\n",
       "\n",
       "    def compute_loss(self, features, training=False):\n",
       "        features, labels = features\n",
       "        rating_predictions = self(features)\n",
       "\n",
       "        return self.task(labels=labels, predictions=rating_predictions)\n",
       "\n",
       "model = MovieRatingModel()\n",
       "\n",
       "# Compile and fit the model with an adjusted learning rate\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
       "\n",
       "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
       "\n",
       "# Evaluate\n",
       "model.evaluate(test_ds)\n",
       "\n",
       "\"\"\"\n",
       "### Observing Changes:\n",
       "\n",
       "When you modify the learning rate to 0.05, it's essential to monitor:\n",
       "\n",
       "- **Training Loss and Validation Loss**: A higher learning rate can lead to faster convergence, but it might also overshoot the minimum, leading to potentially higher loss after initial improvement.\n",
       "- **Accuracy Metrics**: In this case, RMSE (root mean squared error) would be a critical metric. Observe whether it decreases more quickly, stagnates, or even increases due to the higher learning rate.\n",
       "- **Overfitting**: Ensure that the model isn't just memorizing the training data. A significant gap between training and validation metrics might indicate overfitting.\n",
       "\n",
       "If you encounter negative impacts, consider using techniques such as learning rate schedules or decay to adjust the learning rate dynamically during training.\n",
       "\"\"\"\n",
       "```\n",
       "\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_lr_1= helper_extraction_prompt(msg_lr_1)\n",
    "msg_lr_1 = get_resp_oai(prompt_lr_1,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_lr_1, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a41130d-6f7e-41ab-8f71-98557b312f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'movie_rating_model_13', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9596 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 1.9747 - total_loss: 1.9596 - val_loss: 1.2938 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0181 - val_total_loss: 1.2938\n",
      "Epoch 2/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0257 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 1.0363 - total_loss: 1.0257 - val_loss: 1.3845 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0161 - val_total_loss: 1.3845\n",
      "Epoch 3/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9991 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 1.0058 - total_loss: 0.9991 - val_loss: 1.2558 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0092 - val_total_loss: 1.2558\n",
      "Epoch 4/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9777 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9908 - total_loss: 0.9777 - val_loss: 1.2619 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0176 - val_total_loss: 1.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9881 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9913 - total_loss: 0.9881 - val_loss: 1.2396 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0649 - val_total_loss: 1.2396\n",
      "Epoch 6/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9864 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9953 - total_loss: 0.9864 - val_loss: 1.2764 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0513 - val_total_loss: 1.2764\n",
      "Epoch 7/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9648 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9862 - total_loss: 0.9648 - val_loss: 1.2945 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0533 - val_total_loss: 1.2945\n",
      "Epoch 8/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9532 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9805 - total_loss: 0.9532 - val_loss: 1.2659 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0409 - val_total_loss: 1.2659\n",
      "Epoch 9/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9466 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9829 - total_loss: 0.9466 - val_loss: 1.3320 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0414 - val_total_loss: 1.3320\n",
      "Epoch 10/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9559 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9798 - total_loss: 0.9559 - val_loss: 1.3124 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0297 - val_total_loss: 1.3124\n",
      "\u001b[1m26/26\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0704 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9294 - total_loss: 1.0704\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'movie_rating_model_14', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 3.4858 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 2.8410 - total_loss: 3.4858 - val_loss: 1.1050 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0091 - val_total_loss: 1.1050\n",
      "Epoch 2/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9839 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9966 - total_loss: 0.9839 - val_loss: 1.1209 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0077 - val_total_loss: 1.1209\n",
      "Epoch 3/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9658 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9866 - total_loss: 0.9658 - val_loss: 1.1267 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0401 - val_total_loss: 1.1267\n",
      "Epoch 4/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9250 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9716 - total_loss: 0.9250 - val_loss: 1.1386 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0183 - val_total_loss: 1.1386\n",
      "Epoch 5/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9343 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9731 - total_loss: 0.9343 - val_loss: 1.1477 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0159 - val_total_loss: 1.1477\n",
      "Epoch 6/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9330 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9755 - total_loss: 0.9330 - val_loss: 1.1547 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0079 - val_total_loss: 1.1547\n",
      "Epoch 7/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9313 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9741 - total_loss: 0.9313 - val_loss: 1.1629 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0035 - val_total_loss: 1.1629\n",
      "Epoch 8/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9297 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9727 - total_loss: 0.9297 - val_loss: 1.2061 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0009 - val_total_loss: 1.2061\n",
      "Epoch 9/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9227 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9681 - total_loss: 0.9227 - val_loss: 1.1709 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 0.9990 - val_total_loss: 1.1709\n",
      "Epoch 10/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9436 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9738 - total_loss: 0.9436 - val_loss: 1.2205 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.0854 - val_total_loss: 1.2205\n",
      "\u001b[1m26/26\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 1.1799 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 0.9429 - total_loss: 1.1799\n"
     ]
    }
   ],
   "source": [
    "exec(msg_lr_1[len(\"---\\n\\n```python\\n\"):len(msg_lr_1)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb40f2-68e9-49d7-af46-20bf75391d7d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06afb2a-3091-41f1-9fe7-6f83415b5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key= 'H_ClMkEoDcpQkDU4iYaTd3UNMuUUdPDbeQbDVHMnGms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2394c6-f7a4-4457-9675-4758004cc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to communicate with the LLM\n",
    "def get_resp_oai(input_text, model):\n",
    "    url = \"https://llm.api.ai8.io/query_llm\"\n",
    "    data = {\n",
    "        # Specify the model that you want to use\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You act as a highly intelligent system. Your job is to analyse the movie data and predict the rating scores of movies considering various movie features\"},\n",
    "                    {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    }\n",
    "    headers = {'Authorization': api_key}\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        response_data = json.loads(response.content)\n",
    "        model_response = extract_message_oai(response_data)\n",
    "        return model_response\n",
    "    else:\n",
    "        return {\"statusCode\": response.status_code, \"body\": response.content}\n",
    "\n",
    "def extract_message_oai(response_data):\n",
    "    message_content = response_data.get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    # format the extracted message as markdown\n",
    "    markdown_content = \"---\\n\\n\" + message_content + \"\\n\\n---\"\n",
    "    return markdown_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427b7b8a-9b61-4ed0-9f35-44f979c27a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('final_merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7809bf-9f2b-4d84-9c2b-a37a9c942de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'director_name', 'duration', 'actor_2_name', 'genres_x',\n",
      "       'actor_1_name', 'movie_title', 'actor_3_name', 'movie_imdb_link',\n",
      "       'language', 'country', 'title_year', 'imdb_score', 'budget',\n",
      "       'original_title', 'revenue', 'tagline', 'Genre_Action',\n",
      "       'Genre_Adventure', 'Genre_Animation', 'Genre_Biography', 'Genre_Comedy',\n",
      "       'Genre_Crime', 'Genre_Documentary', 'Genre_Drama', 'Genre_Family',\n",
      "       'Genre_Fantasy', 'Genre_Film-Noir', 'Genre_History', 'Genre_Horror',\n",
      "       'Genre_Music', 'Genre_Musical', 'Genre_Mystery', 'Genre_News',\n",
      "       'Genre_Romance', 'Genre_Sci-Fi', 'Genre_Sport', 'Genre_Thriller',\n",
      "       'Genre_War', 'Genre_Western', 'duration_category', 'rating_category',\n",
      "       'budget_category', 'revenue_category', 'budget_revenue_ratio',\n",
      "       'log_budget', 'log_revenue', 'log_title_year', 'sqr_root_duration'],\n",
      "      dtype='object')\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 1s 5ms/step - root_mean_squared_error: 3.9034 - loss: 15.0605 - regularization_loss: 0.0000e+00 - total_loss: 15.0605 - val_root_mean_squared_error: 1.8422 - val_loss: 2.3265 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.3265\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.5892 - loss: 2.4991 - regularization_loss: 0.0000e+00 - total_loss: 2.4991 - val_root_mean_squared_error: 1.2292 - val_loss: 1.0442 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0442\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.1136 - loss: 1.2291 - regularization_loss: 0.0000e+00 - total_loss: 1.2291 - val_root_mean_squared_error: 1.0209 - val_loss: 1.1197 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.1197\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9838 - loss: 0.9610 - regularization_loss: 0.0000e+00 - total_loss: 0.9610 - val_root_mean_squared_error: 0.9866 - val_loss: 1.2669 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2669\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 2ms/step - root_mean_squared_error: 0.9500 - loss: 0.8967 - regularization_loss: 0.0000e+00 - total_loss: 0.8967 - val_root_mean_squared_error: 0.9734 - val_loss: 1.2985 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2985\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9375 - loss: 0.8736 - regularization_loss: 0.0000e+00 - total_loss: 0.8736 - val_root_mean_squared_error: 0.9660 - val_loss: 1.2952 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2952\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9314 - loss: 0.8624 - regularization_loss: 0.0000e+00 - total_loss: 0.8624 - val_root_mean_squared_error: 0.9627 - val_loss: 1.3001 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3001\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9285 - loss: 0.8573 - regularization_loss: 0.0000e+00 - total_loss: 0.8573 - val_root_mean_squared_error: 0.9613 - val_loss: 1.3075 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3075\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 2ms/step - root_mean_squared_error: 0.9263 - loss: 0.8533 - regularization_loss: 0.0000e+00 - total_loss: 0.8533 - val_root_mean_squared_error: 0.9602 - val_loss: 1.3087 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3087\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9250 - loss: 0.8510 - regularization_loss: 0.0000e+00 - total_loss: 0.8510 - val_root_mean_squared_error: 0.9600 - val_loss: 1.3083 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc55cbde290>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and preprocess the dataframe\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Basic preprocessing\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "\n",
    "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "# Correctly structure the dataset for TensorFlow\n",
    "def map_func(features, label):\n",
    "    return features, label\n",
    "\n",
    "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
    "train_labels = np.array(train['imdb_score'])\n",
    "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
    "test_labels = np.array(test['imdb_score'])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "class MovieRatingModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),  # Adjusted input shape\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        \n",
    "        # [ modified bit of code ] #\n",
    "        duration = tf.expand_dims(features['duration'], axis=-1)\n",
    "        genre_action = tf.expand_dims(tf.cast(features['Genre_Action'], tf.float32), axis=-1)\n",
    "        genre_adventure = tf.expand_dims(tf.cast(features['Genre_Adventure'], tf.float32), axis=-1)\n",
    "        genre_animation = tf.expand_dims(tf.cast(features['Genre_Animation'], tf.float32), axis=-1)\n",
    "        budget = tf.expand_dims(features['budget'], axis=-1)\n",
    "        revenue = tf.expand_dims(features['revenue'], axis=-1)\n",
    "\n",
    "        concatenated_features = tf.concat([duration, genre_action, genre_adventure, genre_animation, budget, revenue], axis=1)\n",
    "        # [ modified bit of code ] #\n",
    "        \n",
    "        movie_embeddings = self.movie_model(concatenated_features)\n",
    "        \n",
    "        return self.rating_model(movie_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        features, labels = features\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "# Compile and fit the model\n",
    "model = MovieRatingModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98bfe964-c052-42e1-b290-4d2881dc3e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  Genre_Action  Genre_Adventure  Genre_Animation    budget  \\\n",
      "0  3.133589             1                1                0  4.851404   \n",
      "1  2.725783             1                1                0  6.343649   \n",
      "2  1.774236             1                1                0  5.040895   \n",
      "3  2.499224             1                0                0  5.159328   \n",
      "4  1.049248             1                1                0  5.396192   \n",
      "\n",
      "     revenue  imdb_score  \n",
      "0  15.796650         7.9  \n",
      "1   5.092535         7.1  \n",
      "2   4.621912         6.8  \n",
      "3   5.818689         8.5  \n",
      "4   1.126834         6.6  \n"
     ]
    }
   ],
   "source": [
    "print(df_model.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a01292-c2a8-46ef-8812-bcc6397ed941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain the Random Search task and desired outcomes to the LLM\n",
    "def define_prompt_random_search():\n",
    "    prompt = \"\"\"\n",
    "Task Description:\n",
    "\n",
    "Provide me with the full code that enhances the existing neural network model with a Random Search. This change aims to determine the optimal number of neurons in the first dense layer and optimal learning rate for predicting the IMDB_Score movie ratings.\n",
    "\n",
    "Current Setup:\n",
    "- The model uses TensorFlow and TensorFlow Recommenders libraries.\n",
    "- The model should import keras_tuner using !pip\n",
    "- The model preprocesses the features by including one hot encoded genres and normalized numeric features to input into the neural network.\n",
    "- There are two parts to the neural network: one concatenates movie features and the other predicts movie ratings.\n",
    "\n",
    "Required Modification:\n",
    "- Provide the full code that performs hyperparameter tuning using keras_tuner's Random Search. The output should include the optimal number of neurons in the first dense layer and learning rate for the optimizer. Ensure that your response separates code from explanatory text.\n",
    "\n",
    "Objectives:\n",
    "- Perform hyperparameter tuning to explore different configurations of the number of neurons in the first dense layer and the learning rate.\n",
    "- The hyperparameters identified should optimize the accuracy of the model. \n",
    "- Keep the model architecture unchanged.\n",
    "- Ensure that code is separated from text.\n",
    "- Any text output should be commented out using #\n",
    "\n",
    "Expected Deliverables:\n",
    "1. Adjust the following Python code to perform Random Search hyperparameter tuning and document the changes inline. Provide the python code seperately from the explanations. Make sure that the code combines the full model.\n",
    "2. Consider that the df is already loaded in the environment.\n",
    "\n",
    "\n",
    "This is the already established model:\n",
    "```python\n",
    "# Basic preprocessing\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "\n",
    "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features].copy()  # This is where the copy is made to avoid SettingWithCopyWarning\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "# Correctly structure the dataset for TensorFlow\n",
    "def map_func(features, label):\n",
    "    return features, label\n",
    "\n",
    "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
    "train_labels = np.array(train['imdb_score'])\n",
    "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
    "test_labels = np.array(test['imdb_score'])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "class MovieRatingModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),  # Adjusted input shape\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        \n",
    "        # [ modified bit of code ] #\n",
    "        duration = tf.expand_dims(features['duration'], axis=-1)\n",
    "        genre_action = tf.expand_dims(tf.cast(features['Genre_Action'], tf.float32), axis=-1)\n",
    "        genre_adventure = tf.expand_dims(tf.cast(features['Genre_Adventure'], tf.float32), axis=-1)\n",
    "        genre_animation = tf.expand_dims(tf.cast(features['Genre_Animation'], tf.float32), axis=-1)\n",
    "        budget = tf.expand_dims(features['budget'], axis=-1)\n",
    "        revenue = tf.expand_dims(features['revenue'], axis=-1)\n",
    "        \n",
    "        concatenated_features = tf.concat([duration, genre_action, genre_adventure, genre_animation, budget, revenue], axis=1)\n",
    "        # [ modified bit of code ] #\n",
    "        \n",
    "        movie_embeddings = self.movie_model(concatenated_features)\n",
    "        \n",
    "        return self.rating_model(movie_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        features, labels = features\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "# Compile and fit the model\n",
    "model = MovieRatingModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
    "\n",
    "# Evaluate\n",
    "model.evaluate(test_ds)\n",
    "\n",
    "- Documenting observations:\n",
    " The hyperparameter tuning is intended to optimize the model's performance.\n",
    " Careful monitoring of model performance metrics is crucial to assess the benefits or drawbacks of this adjustment.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ad9a9d-dbd6-42dc-81a0-cf771dfc9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert LLM response string into an executable format\n",
    "def helper_extraction_prompt(resp_str):\n",
    "    return f\"Transform this string: {resp_str} to extract python code. Do not provide any string text or explanations or else it will be an inconvenience and will need to be removed manually. If string text is ouputted, please use # to comment it out. The output will be used directly as Python code :'exec(given_response_string).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35656521-38b5-441e-8998-aa7b4d45f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prompt the model for error resolution \n",
    "def prompt_error(prev_response, err):\n",
    "    return f\"Given that the code you provided: {prev_response} gives this error: {err}, help me resolve it by changing the code you provided where nessesary, your reposne should be in an executable code format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863bf134-9253-4beb-9cbc-fd6430733b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt_rand_search_1 \u001b[38;5;241m=\u001b[39m define_prompt_random_search()\n\u001b[0;32m----> 2\u001b[0m msg_rand_search_1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_resp_oai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_rand_search_1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4-0125-preview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<div style=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor: #34568B;\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg_rand_search_1))\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mget_resp_oai\u001b[0;34m(input_text, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Specify the model that you want to use\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m: api_key}\n\u001b[0;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     14\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompt_rand_search_1 = define_prompt_random_search()\n",
    "msg_rand_search_1 = get_resp_oai(prompt_rand_search_1,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ac21f-4bcd-478e-85d7-520d56875f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_1[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_1)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c699edc-b908-4f28-9017-53ec8d28d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain the error received to the LLM and the adjustements required\n",
    "err = \"\"\" \n",
    "\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File /usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550 in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "\n",
    "  Cell In[51], line 1\n",
    "    exec(msg_rand_search_1[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_1)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "  File <string>:1\n",
    "    hyperparameter tuning using keras_tuner's Random Search for optimizing the number of neurons in the first dense layer and the learning rate for the optimizer, you need to make some modifications and additions to your existing code. Here's how you can incorporate keras_tuner into your workflow:\n",
    "    ^\n",
    "IndentationError: unexpected indent\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# It's recommended to perform hyperparameter tuning using Random Search and to test different dense layer neuron counts and learning rates to make optimal predictions on IMDB_score. \n",
    "\"\"\"\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc40a2c-e534-433c-b56c-3c19de3f322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use prompt_error to define a prompt to resolve the error encountered\n",
    "prompt_rand_search_2 = prompt_error(prev_response, err)\n",
    "msg_rand_search_2 = get_resp_oai(prompt_rand_search_2,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_2, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188681ce-5a9f-4703-8824-f00780008610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_3 = helper_extraction_prompt(msg_rand_search_2)\n",
    "msg_rand_search_3 = get_resp_oai(prompt_rand_search_3,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_3, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a242e-e0ac-4db5-a619-d99dc6e0052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(msg_rand_search_3[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_3)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03d0db-d25a-404c-ad35-ad40bdbefc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain error received to the LLM\n",
    "err = \"\"\" \n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "Cell In[57], line 1\n",
    "----> 1 exec(msg_rand_search_3[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_3)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "File <string>:3\n",
    "\n",
    "ModuleNotFoundError: No module named 'kerastuner'\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# It's recommended to perform hyperparameter tuning using Random Search and to test different dense layer neuron counts and learning rates to make optimal predictions on IMDB_score. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3e2ef-b320-4d3e-8bb3-6f92762f61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use prompt_error to define a prompt to resolve the error encountered\n",
    "prompt_rand_search_4 = prompt_error(prev_response, err)\n",
    "msg_rand_search_4 = get_resp_oai(prompt_rand_search_4,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_4, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c044785-3a49-44fb-9a86-7470e90de565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_5 = helper_extraction_prompt(msg_rand_search_4)\n",
    "msg_rand_search_5 = get_resp_oai(prompt_rand_search_5,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_5, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815e2cb-0e05-47db-b8cb-dbfc65eda48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_5[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_5)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cad7af-977b-4a80-8c28-0d6ec867e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain the error received\n",
    "err = \"\"\" \n",
    "#You are experiencing an error because the 'kerastuner' has been installed incorrectly. It should be installed by using !pip install keras-tuner.\n",
    "\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File /usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550 in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "\n",
    "  Cell In[51], line 1\n",
    "    exec(msg_rand_search_1[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_1)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "  File <string>:1\n",
    "    hyperparameter tuning using keras_tuner's Random Search for optimizing the number of neurons in the first dense layer and the learning rate for the optimizer, you need to make some modifications and additions to your existing code. Here's how you can incorporate keras_tuner into your workflow:\n",
    "    ^\n",
    "IndentationError: unexpected indent\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# With the exception of incorrectly importing kerastuner, the first part of the code was correct until #tuner.search. \n",
    "#The code following tuner_search should be included as a code and not a string.\n",
    "#The code should also apply the tuner search to the validation data.\n",
    "#After performing the hyperparameter search, the best perfoming dense layer neuron count and learning rate should be applied to perform predictions.\n",
    "#After deriving the predictions, the best hyperparamater results should be printed.\n",
    "#The accuracy and the classification report should print the results from the prediction model that incorporated the optimal dense layer neuron count and learning rate. \n",
    "#This was the last code used that needs to be improved using the above criteria: \n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "input_shape = (10,)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='imdb_score_tuning')\n",
    "\n",
    "# tuner.search_space_summary()\n",
    "\n",
    "# X_train, y_train = ...\n",
    "# X_val, y_val = ...\n",
    "\n",
    "# tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# models = tuner.get_best_models(num_models=2)\n",
    "\n",
    "# best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b572187-fd39-4b82-9a22-ae0827945481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reprompt the LLM\n",
    "prompt_rand_search_6 = define_prompt_random_search()\n",
    "msg_rand_search_6 = get_resp_oai(prompt_rand_search_6,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2396f10-5c4f-4998-9722-bd3e6dbdff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_7 = helper_extraction_prompt(msg_rand_search_6)\n",
    "msg_rand_search_7 = get_resp_oai(prompt_rand_search_5,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_7, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b356a3-c916-4124-b351-60e349a3f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_7[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_7)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c705ad-6004-470c-b94a-22c14085a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error received \n",
    "err = \"\"\" \n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "Cell In[65], line 1\n",
    "----> 1 exec(msg_rand_search_7[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_7)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "File <string>:3\n",
    "\n",
    "ModuleNotFoundError: No module named 'kerastuner'\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# You need to install keras tuner using !'pip install keras-tuner' \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da53e7-8113-4f08-8c02-015935ee1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reprompt the LLM\n",
    "prompt_rand_search_8 = define_prompt_random_search()\n",
    "msg_rand_search_8 = get_resp_oai(prompt_rand_search_8,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488ba5e-ac21-4683-a435-0cffb61cb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_9 = helper_extraction_prompt(msg_rand_search_8)\n",
    "msg_rand_search_9 = get_resp_oai(prompt_rand_search_9,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_9, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930136d0-b8fd-40d4-8324-9c1e10a81516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the message\n",
    "exec(msg_rand_search_9[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_9)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d352c-72fe-4480-8380-29c8de6fa1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error received\n",
    "err = \"\"\" \n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "Cell In[69], line 1\n",
    "----> 1 exec(msg_rand_search_9[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_9)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "File <string>:5\n",
    "\n",
    "ModuleNotFoundError: No module named 'keras_tuner'\n",
    "\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# Install !pip install keras-tuner in the first line of code.\n",
    "#Do not hash or comment out the code beginning at tuner.search\n",
    "#Make predictions on the test set after determining the optimal hyperparameters from Random Search\n",
    "#Print the classification report and accuracy of the predictions that use the best hyperparameters found in Random Search\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1430237-e830-41db-9e73-f5fc812f5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reprompt the LLM\n",
    "prompt_rand_search_9 = define_prompt_random_search()\n",
    "msg_rand_search_9 = get_resp_oai(prompt_rand_search_9,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faba86c-6182-4f79-a4b6-9c047f3a20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_10 = helper_extraction_prompt(msg_rand_search_9)\n",
    "msg_rand_search_10 = get_resp_oai(prompt_rand_search_10,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_10, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29914007-37db-4b4a-b1a3-2c670d27c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_10[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_10)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e822027-81db-4ad2-b0cc-1208d1528ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = \"\"\" \n",
    "\n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "Cell In[74], line 1\n",
    "----> 1 exec(msg_rand_search_10[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_10)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "File <string>:5\n",
    "\n",
    "ModuleNotFoundError: No module named 'keras_tuner'\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# The code will not run because not all of the correct modules and packages have been imported. It is very important to load the keras-tuner module using !pip.\n",
    "#The \"import keras_tuner as kt\" does not suffice. In addition to importing this package, the module needs to be imported.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc593507-bc51-4d29-9fa9-5d4429ec582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define using prompting error\n",
    "prompt_rand_search_11 = define_prompt_random_search()\n",
    "msg_rand_search_11 = get_resp_oai(prompt_rand_search_11,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c76b71-b935-483f-8a4f-85718c1b8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_12 = helper_extraction_prompt(msg_rand_search_11)\n",
    "msg_rand_search_12 = get_resp_oai(prompt_rand_search_12,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_12, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af22c7-aa19-476e-8d22-8d8c7df1cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_12[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_12)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074cf8aa-9395-413e-98e2-94f3944420ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error\n",
    "err = \"\"\" \n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File /usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550 in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "\n",
    "  Cell In[80], line 1\n",
    "    exec(msg_rand_search_12[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_12)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "  File <string>:1\n",
    "    !pip install keras-tuner\n",
    "    ^\n",
    "SyntaxError: invalid syntax\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# Remove the !pip install keras-tuner \n",
    "#Do not hash or comment out the code beginning at tuner.search\n",
    "#Make predictions on the test set after determining the optimal hyperparameters from Random Search\n",
    "#Print the classification report and accuracy of the predictions that use the best hyperparameters found in Random Search\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892adc9-1855-423e-b10a-341158f2a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define using prompting error\n",
    "prompt_rand_search_13 = define_prompt_random_search()\n",
    "msg_rand_search_13 = get_resp_oai(prompt_rand_search_13,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267db12d-3cbc-4252-b2fe-29c9f0e4425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_14 = helper_extraction_prompt(msg_rand_search_13)\n",
    "msg_rand_search_14 = get_resp_oai(prompt_rand_search_14,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_14, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f658c64-3a81-4892-bd80-d1c06150e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_14[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_14)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40640a7d-5b0b-4fa7-9a8b-80c7394d5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error received \n",
    "err = \"\"\" \n",
    "\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File /usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550 in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "\n",
    "  Cell In[87], line 1\n",
    "    exec(msg_rand_search_14[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_14)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "  File <string>:1\n",
    "    !pip install keras-tuner\n",
    "    ^\n",
    "SyntaxError: invalid syntax\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# Do not install the keras-tuner module, this means remove the !pip install keras-tuner code.\n",
    "# Add prediction results for the model\n",
    "# Add the accuracy and classification report for the model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b158d-e3b9-4373-9894-ecec21844c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define using prompting error\n",
    "prompt_rand_search_15 = define_prompt_random_search()\n",
    "msg_rand_search_15 = get_resp_oai(prompt_rand_search_15,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c3046-ed6d-48c0-82fa-eb96fde2dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_16 = helper_extraction_prompt(msg_rand_search_15)\n",
    "msg_rand_search_16 = get_resp_oai(prompt_rand_search_16,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_16, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d380e-2f3d-4eab-b134-c23a91451608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_16[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_16)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d25e4-1c6e-409f-8205-9614a5cafff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error received \n",
    "err = \"\"\" \n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[92], line 1\n",
    "----> 1 exec(msg_rand_search_16[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_16)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "File <string>:57\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/keras_tuner/src/tuners/randomsearch.py:164, in RandomSearch.__init__(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\n",
    "    150 def __init__(\n",
    "    151     self,\n",
    "    152     hypermodel=None,\n",
    "   (...)\n",
    "    161     **kwargs\n",
    "    162 ):\n",
    "    163     self.seed = seed\n",
    "--> 164     oracle = RandomSearchOracle(\n",
    "    165         objective=objective,\n",
    "    166         max_trials=max_trials,\n",
    "    167         seed=seed,\n",
    "    168         hyperparameters=hyperparameters,\n",
    "    169         tune_new_entries=tune_new_entries,\n",
    "    170         allow_new_entries=allow_new_entries,\n",
    "    171         max_retries_per_trial=max_retries_per_trial,\n",
    "    172         max_consecutive_failed_trials=max_consecutive_failed_trials,\n",
    "    173     )\n",
    "    174     super().__init__(oracle, hypermodel, **kwargs)\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/keras_tuner/src/tuners/randomsearch.py:73, in RandomSearchOracle.__init__(self, objective, max_trials, seed, hyperparameters, allow_new_entries, tune_new_entries, max_retries_per_trial, max_consecutive_failed_trials)\n",
    "     62 def __init__(\n",
    "     63     self,\n",
    "     64     objective=None,\n",
    "   (...)\n",
    "     71     max_consecutive_failed_trials=3,\n",
    "     72 ):\n",
    "---> 73     super().__init__(\n",
    "     74         objective=objective,\n",
    "     75         max_trials=max_trials,\n",
    "     76         hyperparameters=hyperparameters,\n",
    "     77         tune_new_entries=tune_new_entries,\n",
    "     78         allow_new_entries=allow_new_entries,\n",
    "     79         seed=seed,\n",
    "     80         max_retries_per_trial=max_retries_per_trial,\n",
    "     81         max_consecutive_failed_trials=max_consecutive_failed_trials,\n",
    "     82     )\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:314, in Oracle.__init__(self, objective, max_trials, hyperparameters, allow_new_entries, tune_new_entries, seed, max_retries_per_trial, max_consecutive_failed_trials)\n",
    "    303 def __init__(\n",
    "    304     self,\n",
    "    305     objective=None,\n",
    "   (...)\n",
    "    312     max_consecutive_failed_trials=3,\n",
    "    313 ):\n",
    "--> 314     self.objective = obj_module.create_objective(objective)\n",
    "    315     self.max_trials = max_trials\n",
    "    316     if not hyperparameters:\n",
    "\n",
    "File /usr/local/lib/python3.11/site-packages/keras_tuner/src/engine/objective.py:155, in create_objective(objective)\n",
    "    148     error_msg = (\n",
    "    149         'Could not infer optimization direction (\"min\" or \"max\") '\n",
    "    150         'for unknown metric \"{obj}\". Please specify the objective  as'\n",
    "    151         \"a `keras_tuner.Objective`, for example `keras_tuner.Objective(\"\n",
    "    152         '\"{obj}\", direction=\"min\")`.'\n",
    "    153     )\n",
    "    154     error_msg = error_msg.format(obj=objective)\n",
    "--> 155     raise ValueError(error_msg)\n",
    "    156 return Objective(name=objective, direction=direction)\n",
    "\n",
    "ValueError: Could not infer optimization direction (\"min\" or \"max\") for unknown metric \"val_root_mean_squared_error\". Please specify the objective  asa `keras_tuner.Objective`, for example `keras_tuner.Objective(\"val_root_mean_squared_error\", direction=\"min\")`.\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# The val_root_mean_squared_error in the Objective function needs to be specified with a direction. Either \"val_root_mean_squared_error, direction = min\" or \"val_root_mean_squared_error, direction = \"max\"\n",
    "# In tuner, you must define the hypermodel, hyperparameters, and objective\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d622caf-a4e1-48d0-99da-02ffbf0fbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define using prompting error\n",
    "prompt_rand_search_17 = define_prompt_random_search()\n",
    "msg_rand_search_17 = get_resp_oai(prompt_rand_search_17,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c84fd-5034-49eb-9744-8b7ae9fdc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_18 = helper_extraction_prompt(msg_rand_search_17)\n",
    "msg_rand_search_18 = get_resp_oai(prompt_rand_search_18,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_18, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503120f-8494-4e6d-a311-e31ee51367d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_18[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_18)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab16c5f-c4fc-4879-93e6-b4ed2b2cff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error message\n",
    "err = \"\"\" \n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File /usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550 in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "\n",
    "  Cell In[97], line 1\n",
    "    exec(msg_rand_search_18[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_18)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "  File <string>:1\n",
    "    !pip install -q keras-tuner\n",
    "    ^\n",
    "SyntaxError: invalid syntax\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# Do not install the keras-tuner module, meaning do not use the \"!pip install keras-tuner\" code\n",
    "# The remaining code can be kept the same.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12ea34-07bc-48ac-a01f-1b49d042db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define using prompting error\n",
    "prompt_rand_search_19 = define_prompt_random_search()\n",
    "msg_rand_search_19 = get_resp_oai(prompt_rand_search_19,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e60843-0341-4303-b753-487c647678ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_20 = helper_extraction_prompt(msg_rand_search_19)\n",
    "msg_rand_search_20 = get_resp_oai(prompt_rand_search_20,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_20, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12324922-868b-43fb-8227-02707f1b600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code\n",
    "exec(msg_rand_search_20[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_20)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a617e-bc61-4d41-91be-11c48fbd61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error\n",
    "err = \"\"\" \n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File /usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550 in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "\n",
    "  Cell In[102], line 1\n",
    "    exec(msg_rand_search_20[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_20)-len(\"\\n```\\n\\n---\")])\n",
    "\n",
    "  File <string>:1\n",
    "    !pip install keras-tuner\n",
    "    ^\n",
    "SyntaxError: invalid syntax\n",
    "\"\"\"\n",
    " \n",
    "prev_response = \"\"\"\n",
    "# Do not install the keras-tuner module.\n",
    "# Do not import the keras-tuner module.\n",
    "# The keras-tuner code should not be included. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72089850-1e6a-4842-b75f-7890681f8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define using prompting error\n",
    "prompt_rand_search_21 = define_prompt_random_search()\n",
    "msg_rand_search_21 = get_resp_oai(prompt_rand_search_21,\"gpt-4-0125-preview\")\n",
    "display(Markdown(\"<div style='color: #34568B;'>\\n\\n\" + msg_rand_search_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e41826-58d4-4633-bb80-9faa7348f146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use helper_extraction_prompt to transform the response string into an executable format\n",
    "prompt_rand_search_22 = helper_extraction_prompt(msg_rand_search_21)\n",
    "msg_rand_search_22 = get_resp_oai(prompt_rand_search_22,\"gpt-4-0125-preview\")\n",
    "display(Code(msg_rand_search_22, language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95251cc4-276f-44d5-b7c1-bfd5ea81d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code \n",
    "exec(msg_rand_search_22[len(\"---\\n\\n```python\\n\"):len(msg_rand_search_22)-len(\"\\n```\\n\\n---\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5e5937-cdbb-42e1-848f-17757bcd8622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from random_search/movie_rating_tuning/tuner0.json\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 4s 36ms/step - root_mean_squared_error: 3.4060 - loss: 11.4626 - regularization_loss: 0.0000e+00 - total_loss: 11.4626 - val_root_mean_squared_error: 1.6758 - val_loss: 1.8385 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.8385\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 4s 36ms/step - root_mean_squared_error: 1.3516 - loss: 1.8072 - regularization_loss: 0.0000e+00 - total_loss: 1.8072 - val_root_mean_squared_error: 1.0356 - val_loss: 1.0559 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0559\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 4s 36ms/step - root_mean_squared_error: 0.9837 - loss: 0.9606 - regularization_loss: 0.0000e+00 - total_loss: 0.9606 - val_root_mean_squared_error: 0.9741 - val_loss: 1.2340 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2340\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 4s 37ms/step - root_mean_squared_error: 0.9408 - loss: 0.8793 - regularization_loss: 0.0000e+00 - total_loss: 0.8793 - val_root_mean_squared_error: 0.9668 - val_loss: 1.2448 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2448\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 4s 37ms/step - root_mean_squared_error: 0.9307 - loss: 0.8610 - regularization_loss: 0.0000e+00 - total_loss: 0.8610 - val_root_mean_squared_error: 0.9657 - val_loss: 1.2505 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2505\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 4s 38ms/step - root_mean_squared_error: 0.9272 - loss: 0.8548 - regularization_loss: 0.0000e+00 - total_loss: 0.8548 - val_root_mean_squared_error: 0.9658 - val_loss: 1.2382 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2382\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 4s 38ms/step - root_mean_squared_error: 0.9257 - loss: 0.8521 - regularization_loss: 0.0000e+00 - total_loss: 0.8521 - val_root_mean_squared_error: 0.9662 - val_loss: 1.2446 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2446\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 4s 34ms/step - root_mean_squared_error: 0.9245 - loss: 0.8500 - regularization_loss: 0.0000e+00 - total_loss: 0.8500 - val_root_mean_squared_error: 0.9669 - val_loss: 1.2360 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2360\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 4s 34ms/step - root_mean_squared_error: 0.9239 - loss: 0.8488 - regularization_loss: 0.0000e+00 - total_loss: 0.8488 - val_root_mean_squared_error: 0.9675 - val_loss: 1.2290 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2290\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 4s 37ms/step - root_mean_squared_error: 0.9234 - loss: 0.8481 - regularization_loss: 0.0000e+00 - total_loss: 0.8481 - val_root_mean_squared_error: 0.9680 - val_loss: 1.2245 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2245\n",
      "26/26 [==============================] - 0s 8ms/step\n",
      "26/26 [==============================] - 0s 12ms/step - root_mean_squared_error: 0.9680 - loss: 0.9486 - regularization_loss: 0.0000e+00 - total_loss: 0.9486\n",
      "Root Mean Squared Error: 1.2244938611984253\n",
      "Mean Squared Error: 0\n",
      "26/26 [==============================] - 0s 9ms/step\n",
      "Mean Squared Error: 0.9369372967718164\n",
      "Dense Layer Neuron Count: 192\n",
      "Learning Rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "#Manually updated Random Search using the same structure developed by the LLM\n",
    "\n",
    "#Load the appropriate packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow import keras\n",
    "from keras_tuner import RandomSearch, Objective\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "\n",
    "# Preprocessing\n",
    "df['duration'].fillna(df['duration'].mean(), inplace=True)\n",
    "features = ['duration', 'Genre_Action', 'Genre_Adventure', 'Genre_Animation', 'budget', 'revenue', 'imdb_score']\n",
    "df_model = df[features].copy()\n",
    "\n",
    "# Normalize numeric variables\n",
    "for feature in ['duration', 'budget', 'revenue']:\n",
    "    df_model[feature] = (df_model[feature] - df_model[feature].mean()) / df_model[feature].std()\n",
    "\n",
    "# Split the dataset\n",
    "train = df_model.sample(frac=0.8, random_state=42)\n",
    "test = df_model.drop(train.index)\n",
    "\n",
    "def map_func(features, label):\n",
    "    return features, label\n",
    "\n",
    "#Define the labels and features for training and testing\n",
    "train_features = {name: np.array(value) for name, value in train.drop('imdb_score', axis=1).items()}\n",
    "train_labels = np.array(train['imdb_score'])\n",
    "test_features = {name: np.array(value) for name, value in test.drop('imdb_score', axis=1).items()}\n",
    "test_labels = np.array(test['imdb_score'])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).map(map_func)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).map(map_func)\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "objective = Objective('root_mean_squared_error', direction = \"min\")\n",
    "\n",
    "#Construct the neural network\n",
    "def build_model(hp):\n",
    "    class MovieRatingModel(tfrs.Model):\n",
    "        def __init__(self, hp):\n",
    "            super().__init__()\n",
    "            self.movie_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "                tf.keras.layers.Dense(32, activation='relu')\n",
    "            ])\n",
    "            self.rating_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "            self.task = tfrs.tasks.Ranking(\n",
    "                loss=tf.keras.losses.MeanSquaredError(),\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "            )\n",
    "        \n",
    "        def call(self, features):\n",
    "            concatenated_features = tf.concat(\n",
    "                [tf.expand_dims(tf.cast(features[name], tf.float32), -1) for name in features],\n",
    "                axis=1\n",
    "            )\n",
    "            movie_embeddings = self.movie_model(concatenated_features)\n",
    "            return self.rating_model(movie_embeddings)\n",
    "            \n",
    "        def compute_loss(self, features, training=False):\n",
    "            features, labels = features  \n",
    "            rating_predictions = self(features)  \n",
    "            loss = self.task(labels=labels, predictions=rating_predictions)  \n",
    "            return loss + sum(self.losses)  \n",
    "\n",
    "    model = MovieRatingModel(hp)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        run_eagerly=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "#Construct Random Search\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective= objective,\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='random_search',\n",
    "    project_name='movie_rating_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(train_ds, epochs=10, validation_data=test_ds)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "best_model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
    "\n",
    "#Transform the test sets labels \n",
    "y_true = np.concatenate([y.numpy() if y.ndim > 0 else np.array([y.numpy()]) for x, y in test_ds.unbatch()])\n",
    "\n",
    "#Make predictions \n",
    "y_pred = best_model.predict(test_ds)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1) \n",
    "\n",
    "#Evaluate \n",
    "results = best_model.evaluate(test_ds)\n",
    "\n",
    "#Regression Results\n",
    "print(\"Root Mean Squared Error:\", results[1])  \n",
    "print(\"Mean Squared Error:\", results[2])      \n",
    "\n",
    "#Make predictions using the optimal hyperparameters\n",
    "y_pred = best_model.predict(test_ds)\n",
    "y_pred = np.squeeze(y_pred)\n",
    "\n",
    "#Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "#Best hyperparameters\n",
    "print(\"Dense Layer Neuron Count:\", best_hps.get('units'))\n",
    "print(\"Learning Rate:\", best_hps.get('learning_rate'))\n"
   ]
  }
 ],
 "metadata": {
  "ai8-sym": {
   "notebook_id": "7889032f-2ff7-48a3-b7b7-5645e53e9cb7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
